"""
Aplica√ß√£o principal FastAPI.
"""
from fastapi import FastAPI, Depends, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy.orm import Session
from sqlalchemy import text
from typing import Optional, List
from datetime import date, datetime
from pydantic import BaseModel
import uvicorn

from loguru import logger

from config import settings
from database import get_db, init_db, OperacaoComex, TipoOperacao, ViaTransporte
from data_collector import DataCollector

# Import opcional do router de exporta√ß√£o
try:
    from api.export import router as export_router
    EXPORT_ROUTER_AVAILABLE = True
except ImportError:
    EXPORT_ROUTER_AVAILABLE = False
    logger.warning("Router de exporta√ß√£o n√£o dispon√≠vel")

# Imports opcionais para funcionalidades de autentica√ß√£o
try:
    from database.models import Usuario, AprovacaoCadastro
    AUTH_AVAILABLE = True
except ImportError:
    AUTH_AVAILABLE = False
    logger.warning("Modelos de autentica√ß√£o n√£o dispon√≠veis")

try:
    from auth import authenticate_user, create_access_token, get_current_user, get_password_hash, validate_password
    AUTH_FUNCTIONS_AVAILABLE = True
except ImportError:
    AUTH_FUNCTIONS_AVAILABLE = False
    logger.warning("Fun√ß√µes de autentica√ß√£o n√£o dispon√≠veis")

try:
    from services.email_service import enviar_email_aprovacao, enviar_email_cadastro_aprovado
    EMAIL_SERVICE_AVAILABLE = True
except ImportError:
    EMAIL_SERVICE_AVAILABLE = False
    logger.warning("Servi√ßo de email n√£o dispon√≠vel")

# Inicializar app FastAPI
app = FastAPI(
    title="Comex Analyzer API",
    description="API para an√°lise de dados do com√©rcio exterior brasileiro",
    version="1.0.0"
)

# Configurar CORS para permitir requisi√ß√µes do frontend Electron
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Em produ√ß√£o, especificar origem do Electron
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Incluir routers
if EXPORT_ROUTER_AVAILABLE:
    app.include_router(export_router)


# Inicializar banco de dados na startup
@app.on_event("startup")
async def startup_event():
    """Inicializa o banco de dados na startup."""
    try:
        init_db()
        logger.info("Banco de dados inicializado")
    except Exception as e:
        logger.error(f"Erro ao inicializar banco de dados: {e}")
        # N√£o interrompe a aplica√ß√£o, mas loga o erro
    
    # Iniciar scheduler para atualiza√ß√£o di√°ria
    try:
        from utils.scheduler import DataScheduler
        scheduler = DataScheduler()
        scheduler.start()
        logger.info("Scheduler de atualiza√ß√£o di√°ria iniciado")
        
        # Executar atualiza√ß√£o inicial de empresas e sinergias em background
        async def atualizacao_inicial():
            try:
                from utils.data_updater import DataUpdater
                updater = DataUpdater()
                logger.info("Iniciando atualiza√ß√£o inicial de empresas MDIC e sinergias...")
                await updater.atualizar_empresas_mdic()
                await updater.atualizar_relacionamentos(limite=500)  # Limite menor na inicializa√ß√£o
                await updater.atualizar_sinergias(limite_empresas=50)  # Limite menor na inicializa√ß√£o
                logger.info("‚úÖ Atualiza√ß√£o inicial conclu√≠da")
            except Exception as e:
                logger.warning(f"Atualiza√ß√£o inicial n√£o executada: {e}")
        
        # Executar ap√≥s 30 segundos (dar tempo para o servidor inicializar)
        import asyncio
        import threading
        def run_initial_update():
            import time
            time.sleep(30)
            asyncio.run(atualizacao_inicial())
        
        update_thread = threading.Thread(target=run_initial_update, daemon=True)
        update_thread.start()
        
    except Exception as e:
        logger.warning(f"N√£o foi poss√≠vel iniciar scheduler: {e}")
        # N√£o interrompe a aplica√ß√£o se o scheduler falhar


# Schemas Pydantic
class OperacaoResponse(BaseModel):
    """Schema de resposta para opera√ß√£o."""
    id: int
    ncm: str
    descricao_produto: str
    tipo_operacao: str
    pais_origem_destino: str
    uf: str
    valor_fob: float
    data_operacao: date
    
    class Config:
        from_attributes = True


class DashboardStats(BaseModel):
    """Estat√≠sticas do dashboard."""
    volume_importacoes: float
    volume_exportacoes: float
    valor_total_usd: float
    valor_total_importacoes: Optional[float] = None  # Valor total de importa√ß√µes
    valor_total_exportacoes: Optional[float] = None  # Valor total de exporta√ß√µes
    principais_ncms: List[dict]
    principais_paises: List[dict]
    registros_por_mes: dict
    valores_por_mes: Optional[dict] = None  # Valores FOB por m√™s
    pesos_por_mes: Optional[dict] = None  # Pesos por m√™s


class BuscaFiltros(BaseModel):
    """Filtros de busca."""
    ncms: Optional[List[str]] = None  # Lista de NCMs
    ncm: Optional[str] = None  # Mantido para compatibilidade
    data_inicio: Optional[date] = None
    data_fim: Optional[date] = None
    tipo_operacao: Optional[str] = None
    pais: Optional[str] = None
    uf: Optional[str] = None
    via_transporte: Optional[str] = None
    valor_fob_min: Optional[float] = None
    valor_fob_max: Optional[float] = None
    peso_min: Optional[float] = None
    peso_max: Optional[float] = None
    empresa_importadora: Optional[str] = None
    empresa_exportadora: Optional[str] = None
    page: int = 1
    page_size: int = 100


# Endpoints
@app.get("/")
async def root():
    """Endpoint raiz."""
    return {
        "message": "Comex Analyzer API",
        "version": "1.0.0",
        "status": "online"
    }


@app.get("/health")
async def health_check(db: Session = Depends(get_db)):
    """Verifica sa√∫de da API."""
    try:
        # Testar conex√£o com banco
        db.execute(text("SELECT 1"))
        db.commit()
        return {"status": "healthy", "database": "connected"}
    except Exception as e:
        logger.error(f"Health check error: {e}")
        return {"status": "unhealthy", "error": str(e)}


@app.post("/coletar-dados")
async def coletar_dados(db: Session = Depends(get_db)):
    """
    Inicia coleta de dados do Comex Stat.
    """
    try:
        collector = DataCollector()
        stats = await collector.collect_recent_data(db)
        
        return {
            "success": True,
            "message": "Coleta de dados conclu√≠da",
            "stats": stats
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao coletar dados: {str(e)}")


@app.post("/coletar-dados-enriquecidos")
async def coletar_dados_enriquecidos(
    meses: int = Query(24, description="N√∫mero de meses para coletar"),
    db: Session = Depends(get_db)
):
    """
    Coleta dados CSV do portal oficial do MDIC e enriquece com empresas e CNAE.
    Este endpoint:
    1. Baixa tabelas de correla√ß√£o do MDIC
    2. Baixa dados mensais de importa√ß√£o/exporta√ß√£o dos √∫ltimos N meses
    3. Processa e salva no banco de dados
    4. Enriquece com informa√ß√µes de empresas do MDIC
    5. Integra com CNAE para sugest√µes inteligentes
    
    Fonte: https://www.gov.br/mdic/pt-br/assuntos/comercio-exterior/estatisticas/base-de-dados-bruta
    """
    try:
        from data_collector.enriched_collector import EnrichedDataCollector
        
        logger.info(f"Iniciando coleta enriquecida de dados do MDIC ({meses} meses)...")
        
        collector = EnrichedDataCollector()
        stats = await collector.collect_and_enrich(db, meses)
        
        return {
            "success": True,
            "message": "Coleta enriquecida conclu√≠da",
            "stats": stats,
            "tabelas_baixadas": list(stats.get("tabelas_correlacao", {}).keys()),
            "empresas_enriquecidas": stats.get("empresas_enriquecidas", 0)
        }
    except Exception as e:
        logger.error(f"Erro na coleta enriquecida: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erro na coleta enriquecida: {str(e)}")


class ColetarDadosNCMsRequest(BaseModel):
    """Schema para coletar dados de m√∫ltiplos NCMs."""
    ncms: Optional[List[str]] = None  # Lista de NCMs espec√≠ficos (None = todos)
    meses: Optional[int] = 24  # Quantos meses buscar (padr√£o: 24)
    tipo_operacao: Optional[str] = None  # "Importa√ß√£o" ou "Exporta√ß√£o" (None = ambos)


@app.post("/coletar-dados-ncms")
async def coletar_dados_ncms(
    request: ColetarDadosNCMsRequest,
    db: Session = Depends(get_db)
):
    """
    Coleta dados reais da API Comex Stat ou CSV scraper para m√∫ltiplos NCMs.
    Sistema de fallback autom√°tico:
    1. Tenta API REST primeiro
    2. Se falhar, usa CSV scraper (bases de dados brutas)
    3. Se falhar, usa scraper tradicional (se dispon√≠vel)
    
    Se ncms n√£o for fornecido, coleta dados gerais (todos os NCMs).
    """
    try:
        from datetime import datetime, timedelta
        from data_collector import DataCollector
        
        collector = DataCollector()
        stats = {
            "total_registros": 0,
            "meses_processados": [],
            "erros": [],
            "ncms_processados": [],
            "usou_api": False,
            "metodo_usado": "desconhecido"
        }
        
        # Calcular meses a buscar
        meses = request.meses or 24
        hoje = datetime.now()
        meses_lista = []
        for i in range(meses):
            mes_date = hoje - timedelta(days=30 * i)
            meses_lista.append(mes_date.strftime("%Y-%m"))
        meses_lista = sorted(meses_lista)
        
        # Se n√£o especificar NCMs, usar m√©todo coletivo (mais eficiente)
        if not request.ncms or len(request.ncms) == 0:
            logger.info(f"Coletando dados gerais (todos os NCMs) para {meses} meses...")
            logger.info("Sistema tentar√°: API ‚Üí CSV Scraper ‚Üí Scraper tradicional")
            
            # Usar o m√©todo coletivo do DataCollector que tem fallback autom√°tico
            try:
                # Ajustar meses no collector temporariamente
                original_months = settings.months_to_fetch
                settings.months_to_fetch = meses
                
                # Coletar dados (com fallback autom√°tico)
                collection_stats = await collector.collect_recent_data(db)
                
                # Restaurar configura√ß√£o
                settings.months_to_fetch = original_months
                
                stats.update(collection_stats)
                stats["metodo_usado"] = "API" if collection_stats.get("usou_api") else "CSV Scraper ou Scraper"
                
            except Exception as e:
                logger.error(f"Erro na coleta coletiva: {e}")
                stats["erros"].append(f"Coleta coletiva: {str(e)}")
        else:
            # Coletar dados espec√≠ficos de cada NCM (via API apenas por enquanto)
            logger.info(f"Coletando dados para {len(request.ncms)} NCMs espec√≠ficos...")
            
            # Verificar se API est√° dispon√≠vel
            if await collector.api_client.test_connection():
                stats["usou_api"] = True
                stats["metodo_usado"] = "API"
                
                for ncm in request.ncms:
                    ncm_limpo = ncm.replace('.', '').replace(' ', '').strip()
                    if len(ncm_limpo) != 8 or not ncm_limpo.isdigit():
                        logger.warning(f"NCM inv√°lido ignorado: {ncm}")
                        continue
                    
                    try:
                        tipos = ["Importa√ß√£o", "Exporta√ß√£o"]
                        if request.tipo_operacao:
                            tipos = [request.tipo_operacao]
                        
                        for tipo in tipos:
                            logger.info(f"Coletando NCM {ncm_limpo} - {tipo}...")
                            for mes in meses_lista:
                                try:
                                    data = await collector.api_client.fetch_data(
                                        mes_inicio=mes,
                                        mes_fim=mes,
                                        tipo_operacao=tipo,
                                        ncm=ncm_limpo
                                    )
                                    
                                    if data:
                                        transformed = collector.transformer.transform_api_data(data, mes, tipo)
                                        saved = collector._save_to_database(db, transformed, mes, tipo)
                                        stats["total_registros"] += saved
                                
                                except Exception as e:
                                    logger.warning(f"Erro ao coletar {ncm_limpo} - {mes}: {e}")
                                    continue
                        
                        stats["ncms_processados"].append(ncm_limpo)
                        logger.info(f"‚úì NCM {ncm_limpo} processado")
                    except Exception as e:
                        error_msg = f"Erro ao coletar NCM {ncm}: {e}"
                        logger.error(error_msg)
                        stats["erros"].append(error_msg)
            else:
                # Se API n√£o dispon√≠vel e NCMs espec√≠ficos, sugerir coleta geral
                stats["erros"].append(
                    "API n√£o dispon√≠vel para NCMs espec√≠ficos. "
                    "Use coleta geral (sem especificar NCMs) para usar CSV scraper."
                )
        
        return {
            "success": True,
            "message": f"Coleta conclu√≠da: {stats['total_registros']} registros usando {stats.get('metodo_usado', 'desconhecido')}",
            "stats": stats
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erro ao coletar dados: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erro ao coletar dados: {str(e)}")


class PopularDadosRequest(BaseModel):
    """Schema para popular dados de exemplo."""
    quantidade: int = 1000
    meses: int = 24


@app.post("/popular-dados-exemplo")
async def popular_dados_exemplo(
    request: PopularDadosRequest,
    db: Session = Depends(get_db)
):
    """
    Popula o banco de dados com dados de exemplo.
    √ötil para testes quando n√£o h√° acesso ao Shell.
    """
    try:
        from scripts.popular_dados_exemplo import gerar_dados_exemplo
        
        logger.info(f"Iniciando popula√ß√£o de {request.quantidade} registros...")
        
        registros_criados = gerar_dados_exemplo(request.quantidade)
        
        # Verificar quantas empresas foram criadas
        from sqlalchemy import func, distinct
        total_importadoras = db.query(func.count(distinct(OperacaoComex.razao_social_importador))).filter(
            OperacaoComex.razao_social_importador.isnot(None),
            OperacaoComex.razao_social_importador != ''
        ).scalar() or 0
        
        total_exportadoras = db.query(func.count(distinct(OperacaoComex.razao_social_exportador))).filter(
            OperacaoComex.razao_social_exportador.isnot(None),
            OperacaoComex.razao_social_exportador != ''
        ).scalar() or 0
        
        return {
            "success": True,
            "message": f"Banco populado com {registros_criados} registros",
            "registros_criados": registros_criados,
            "quantidade_solicitada": request.quantidade,
            "empresas_importadoras": total_importadoras or 0,
            "empresas_exportadoras": total_exportadoras or 0
        }
    except Exception as e:
        logger.error(f"Erro ao popular dados: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erro ao popular dados: {str(e)}")


@app.get("/test/empresas")
async def test_empresas(db: Session = Depends(get_db)):
    """
    Endpoint de teste para verificar empresas no banco.
    """
    from sqlalchemy import func, distinct
    
    try:
        # Contar total de registros
        total_registros = db.query(OperacaoComex).count()
        
        # Contar empresas importadoras distintas
        importadoras = db.query(
            distinct(OperacaoComex.razao_social_importador)
        ).filter(
            OperacaoComex.razao_social_importador.isnot(None),
            OperacaoComex.razao_social_importador != ''
        ).limit(10).all()
        
        # Contar empresas exportadoras distintas
        exportadoras = db.query(
            distinct(OperacaoComex.razao_social_exportador)
        ).filter(
            OperacaoComex.razao_social_exportador.isnot(None),
            OperacaoComex.razao_social_exportador != ''
        ).limit(10).all()
        
        # Contar totais distintos
        total_imp_distintas = db.query(
            func.count(distinct(OperacaoComex.razao_social_importador))
        ).filter(
            OperacaoComex.razao_social_importador.isnot(None),
            OperacaoComex.razao_social_importador != ''
        ).scalar() or 0
        
        total_exp_distintas = db.query(
            func.count(distinct(OperacaoComex.razao_social_exportador))
        ).filter(
            OperacaoComex.razao_social_exportador.isnot(None),
            OperacaoComex.razao_social_exportador != ''
        ).scalar() or 0
        
        # Valores totais
        valor_total_imp = db.query(func.sum(OperacaoComex.valor_fob)).filter(
            OperacaoComex.tipo_operacao == TipoOperacao.IMPORTACAO
        ).scalar() or 0
        
        valor_total_exp = db.query(func.sum(OperacaoComex.valor_fob)).filter(
            OperacaoComex.tipo_operacao == TipoOperacao.EXPORTACAO
        ).scalar() or 0
        
        # Testar autocomplete
        teste_autocomplete_imp = db.query(
            OperacaoComex.razao_social_importador.label('empresa'),
            func.count(OperacaoComex.id).label('total_operacoes')
        ).filter(
            OperacaoComex.razao_social_importador.isnot(None),
            OperacaoComex.razao_social_importador != '',
            OperacaoComex.razao_social_importador.ilike("%Importadora%")
        ).group_by(
            OperacaoComex.razao_social_importador
        ).limit(5).all()
        
        teste_autocomplete_exp = db.query(
            OperacaoComex.razao_social_exportador.label('empresa'),
            func.count(OperacaoComex.id).label('total_operacoes')
        ).filter(
            OperacaoComex.razao_social_exportador.isnot(None),
            OperacaoComex.razao_social_exportador != '',
            OperacaoComex.razao_social_exportador.ilike("%Exportadora%")
        ).group_by(
            OperacaoComex.razao_social_exportador
        ).limit(5).all()
        
        return {
            "total_registros": total_registros,
            "exemplo_importadoras": [imp[0] for imp in importadoras if imp[0]],
            "exemplo_exportadoras": [exp[0] for exp in exportadoras if exp[0]],
            "total_importadoras_distintas": total_imp_distintas,
            "total_exportadoras_distintas": total_exp_distintas,
            "valor_total_importacoes": float(valor_total_imp),
            "valor_total_exportacoes": float(valor_total_exp),
            "teste_autocomplete_importadoras": [
                {"nome": emp, "total_operacoes": int(total)} 
                for emp, total in teste_autocomplete_imp
            ],
            "teste_autocomplete_exportadoras": [
                {"nome": emp, "total_operacoes": int(total)} 
                for emp, total in teste_autocomplete_exp
            ],
            "status": "ok" if total_registros > 0 else "vazio",
            "problemas": [
                "Banco est√° vazio" if total_registros == 0 else None,
                "Nenhuma empresa importadora" if total_imp_distintas == 0 else None,
                "Nenhuma empresa exportadora" if total_exp_distintas == 0 else None,
            ]
        }
    except Exception as e:
        logger.error(f"Erro ao testar empresas: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return {"erro": str(e), "traceback": traceback.format_exc()}


@app.get("/dashboard/stats", response_model=DashboardStats)
async def get_dashboard_stats(
    meses: int = Query(default=24, ge=1, le=24),  # Padr√£o: 2 anos
    tipo_operacao: Optional[str] = Query(default=None),
    ncm: Optional[str] = Query(default=None),
    ncms: Optional[List[str]] = Query(default=None),  # M√∫ltiplos NCMs
    empresa_importadora: Optional[str] = Query(default=None),
    empresa_exportadora: Optional[str] = Query(default=None),
    db: Session = Depends(get_db)
):
    """
    Retorna estat√≠sticas para o dashboard.
    Por padr√£o busca √∫ltimos 2 anos (24 meses).
    """
    from sqlalchemy import func, and_, or_
    from datetime import datetime, timedelta
    
    # Calcular data inicial (padr√£o: 2 anos)
    data_inicio = datetime.now() - timedelta(days=30 * meses)
    
    # Construir filtros base
    base_filters = [OperacaoComex.data_operacao >= data_inicio.date()]
    
    # Aplicar filtro de NCMs (m√∫ltiplos ou √∫nico)
    ncms_filtro = []
    if ncms:
        for ncm_item in ncms:
            ncm_limpo = ncm_item.replace('.', '').replace(' ', '').strip()
            if len(ncm_limpo) == 8 and ncm_limpo.isdigit():
                ncms_filtro.append(ncm_limpo)
    elif ncm:
        ncm_limpo = ncm.replace('.', '').replace(' ', '').strip()
        if len(ncm_limpo) == 8 and ncm_limpo.isdigit():
            ncms_filtro.append(ncm_limpo)
    
    if ncms_filtro:
        if len(ncms_filtro) == 1:
            base_filters.append(OperacaoComex.ncm == ncms_filtro[0])
        else:
            base_filters.append(OperacaoComex.ncm.in_(ncms_filtro))
    
    # Aplicar filtros de empresa
    if empresa_importadora:
        base_filters.append(
            OperacaoComex.razao_social_importador.ilike(f"%{empresa_importadora}%")
        )
    
    if empresa_exportadora:
        base_filters.append(
            OperacaoComex.razao_social_exportador.ilike(f"%{empresa_exportadora}%")
        )
    
    # Aplicar filtro de tipo de opera√ß√£o se fornecido
    tipo_filtro = None
    if tipo_operacao:
        if tipo_operacao.lower() == "importa√ß√£o" or tipo_operacao.lower() == "importacao":
            tipo_filtro = TipoOperacao.IMPORTACAO
        elif tipo_operacao.lower() == "exporta√ß√£o" or tipo_operacao.lower() == "exportacao":
            tipo_filtro = TipoOperacao.EXPORTACAO
    
    # Volume de importa√ß√µes e exporta√ß√µes
    filtros_imp = base_filters + [OperacaoComex.tipo_operacao == TipoOperacao.IMPORTACAO]
    if tipo_filtro == TipoOperacao.IMPORTACAO or tipo_filtro is None:
        volume_imp = db.query(func.sum(OperacaoComex.peso_liquido_kg)).filter(
            and_(*filtros_imp)
        ).scalar() or 0.0
    else:
        volume_imp = 0.0
    
    filtros_exp = base_filters + [OperacaoComex.tipo_operacao == TipoOperacao.EXPORTACAO]
    if tipo_filtro == TipoOperacao.EXPORTACAO or tipo_filtro is None:
        volume_exp = db.query(func.sum(OperacaoComex.peso_liquido_kg)).filter(
            and_(*filtros_exp)
        ).scalar() or 0.0
    else:
        volume_exp = 0.0
    
    # Valor total movimentado
    if tipo_filtro:
        filtros_valor = base_filters + [OperacaoComex.tipo_operacao == tipo_filtro]
    else:
        filtros_valor = base_filters
    
    valor_total = db.query(func.sum(OperacaoComex.valor_fob)).filter(
        and_(*filtros_valor)
    ).scalar() or 0.0
    
    # Valores separados por tipo de opera√ß√£o (se n√£o houver filtro de tipo)
    valor_total_imp = 0.0
    valor_total_exp = 0.0
    if tipo_filtro is None:
        # Calcular valores separados apenas se n√£o houver filtro de tipo
        filtros_valor_imp = base_filters + [OperacaoComex.tipo_operacao == TipoOperacao.IMPORTACAO]
        valor_total_imp = db.query(func.sum(OperacaoComex.valor_fob)).filter(
            and_(*filtros_valor_imp)
        ).scalar() or 0.0
        
        filtros_valor_exp = base_filters + [OperacaoComex.tipo_operacao == TipoOperacao.EXPORTACAO]
        valor_total_exp = db.query(func.sum(OperacaoComex.valor_fob)).filter(
            and_(*filtros_valor_exp)
        ).scalar() or 0.0
    elif tipo_filtro == TipoOperacao.IMPORTACAO:
        valor_total_imp = valor_total
    elif tipo_filtro == TipoOperacao.EXPORTACAO:
        valor_total_exp = valor_total
    
    # Principais NCMs
    principais_ncms = db.query(
        OperacaoComex.ncm,
        OperacaoComex.descricao_produto,
        func.sum(OperacaoComex.valor_fob).label('total_valor'),
        func.count(OperacaoComex.id).label('total_operacoes')
    ).filter(
        and_(*filtros_valor)
    ).group_by(
        OperacaoComex.ncm,
        OperacaoComex.descricao_produto
    ).order_by(
        func.sum(OperacaoComex.valor_fob).desc()
    ).limit(10).all()
    
    principais_ncms_list = [
        {
            "ncm": ncm,
            "descricao": desc[:100] if desc else "",
            "valor_total": float(total_valor),
            "total_operacoes": total_operacoes
        }
        for ncm, desc, total_valor, total_operacoes in principais_ncms
    ]
    
    # Principais pa√≠ses
    principais_paises = db.query(
        OperacaoComex.pais_origem_destino,
        func.sum(OperacaoComex.valor_fob).label('total_valor'),
        func.count(OperacaoComex.id).label('total_operacoes')
    ).filter(
        and_(*filtros_valor)
    ).group_by(
        OperacaoComex.pais_origem_destino
    ).order_by(
        func.sum(OperacaoComex.valor_fob).desc()
    ).limit(10).all()
    
    principais_paises_list = [
        {
            "pais": pais,
            "valor_total": float(total_valor),
            "total_operacoes": total_operacoes
        }
        for pais, total_valor, total_operacoes in principais_paises
    ]
    
    # Registros por m√™s com valores FOB e peso
    registros_por_mes_query = db.query(
        OperacaoComex.mes_referencia,
        func.count(OperacaoComex.id).label('count'),
        func.sum(OperacaoComex.valor_fob).label('valor_total'),
        func.sum(OperacaoComex.peso_liquido_kg).label('peso_total')
    ).filter(
        and_(*filtros_valor)
    ).group_by(
        OperacaoComex.mes_referencia
    ).order_by(
        OperacaoComex.mes_referencia
    ).all()
    
    registros_dict = {
        mes: count for mes, count, _, _ in registros_por_mes_query
    }
    
    valores_por_mes_dict = {
        mes: float(valor_total) if valor_total else 0.0
        for mes, _, valor_total, _ in registros_por_mes_query
    }
    
    pesos_por_mes_dict = {
        mes: float(peso_total) if peso_total else 0.0
        for mes, _, _, peso_total in registros_por_mes_query
    }
    
    stats_response = DashboardStats(
        volume_importacoes=float(volume_imp),
        volume_exportacoes=float(volume_exp),
        valor_total_usd=float(valor_total),
        valor_total_importacoes=float(valor_total_imp) if valor_total_imp else None,
        valor_total_exportacoes=float(valor_total_exp) if valor_total_exp else None,
        principais_ncms=principais_ncms_list,
        principais_paises=principais_paises_list,
        registros_por_mes=registros_dict,
        valores_por_mes=valores_por_mes_dict if valores_por_mes_dict else {},
        pesos_por_mes=pesos_por_mes_dict if pesos_por_mes_dict else {}
    )
    
    return stats_response


@app.post("/buscar")
async def buscar_operacoes(
    filtros: BuscaFiltros,
    db: Session = Depends(get_db)
):
    """
    Busca opera√ß√µes com filtros avan√ßados.
    Por padr√£o, busca dados dos √∫ltimos 2 anos se n√£o especificar datas.
    """
    from sqlalchemy import and_, or_
    from datetime import datetime, timedelta
    
    query = db.query(OperacaoComex)
    
    # Aplicar filtros
    conditions = []
    
    # Filtro de NCMs (m√∫ltiplos)
    ncms_filtro = []
    if filtros.ncms:
        # Limpar e validar NCMs
        for ncm in filtros.ncms:
            ncm_limpo = ncm.replace('.', '').replace(' ', '').strip()
            if len(ncm_limpo) == 8 and ncm_limpo.isdigit():
                ncms_filtro.append(ncm_limpo)
    elif filtros.ncm:
        # Compatibilidade: aceitar NCM √∫nico tamb√©m
        ncm_limpo = filtros.ncm.replace('.', '').replace(' ', '').strip()
        if len(ncm_limpo) == 8 and ncm_limpo.isdigit():
            ncms_filtro.append(ncm_limpo)
    
    if ncms_filtro:
        conditions.append(OperacaoComex.ncm.in_(ncms_filtro))
    
    # Por padr√£o, buscar √∫ltimos 2 anos se n√£o especificar datas
    if not filtros.data_inicio:
        filtros.data_inicio = (datetime.now() - timedelta(days=730)).date()
    if not filtros.data_fim:
        filtros.data_fim = datetime.now().date()
    
    conditions.append(OperacaoComex.data_operacao >= filtros.data_inicio)
    conditions.append(OperacaoComex.data_operacao <= filtros.data_fim)
    
    if filtros.tipo_operacao:
        tipo = TipoOperacao.IMPORTACAO if filtros.tipo_operacao == "Importa√ß√£o" else TipoOperacao.EXPORTACAO
        conditions.append(OperacaoComex.tipo_operacao == tipo)
    
    if filtros.pais:
        conditions.append(OperacaoComex.pais_origem_destino.ilike(f"%{filtros.pais}%"))
    
    if filtros.uf:
        conditions.append(OperacaoComex.uf == filtros.uf.upper())
    
    if filtros.via_transporte:
        via = ViaTransporte[filtros.via_transporte.upper()]
        conditions.append(OperacaoComex.via_transporte == via)
    
    # Filtros de empresa
    if filtros.empresa_importadora:
        conditions.append(
            OperacaoComex.razao_social_importador.ilike(f"%{filtros.empresa_importadora}%")
        )
    
    if filtros.empresa_exportadora:
        conditions.append(
            OperacaoComex.razao_social_exportador.ilike(f"%{filtros.empresa_exportadora}%")
        )
    
    if filtros.valor_fob_min:
        conditions.append(OperacaoComex.valor_fob >= filtros.valor_fob_min)
    
    if filtros.valor_fob_max:
        conditions.append(OperacaoComex.valor_fob <= filtros.valor_fob_max)
    
    if filtros.peso_min:
        conditions.append(OperacaoComex.peso_liquido_kg >= filtros.peso_min)
    
    if filtros.peso_max:
        conditions.append(OperacaoComex.peso_liquido_kg <= filtros.peso_max)
    
    if conditions:
        query = query.filter(and_(*conditions))
    
    # Contar total
    total = query.count()
    
    # Pagina√ß√£o
    offset = (filtros.page - 1) * filtros.page_size
    operacoes = query.order_by(
        OperacaoComex.data_operacao.desc()
    ).offset(offset).limit(filtros.page_size).all()
    
    return {
        "total": total,
        "page": filtros.page,
        "page_size": filtros.page_size,
        "total_pages": (total + filtros.page_size - 1) // filtros.page_size,
        "results": [
            {
                "id": op.id,
                "ncm": op.ncm,
                "descricao_produto": op.descricao_produto,
                "tipo_operacao": op.tipo_operacao.value,
                "pais_origem_destino": op.pais_origem_destino,
                "uf": op.uf,
                "valor_fob": op.valor_fob,
                "peso_liquido_kg": op.peso_liquido_kg,
                "data_operacao": op.data_operacao.isoformat(),
                "razao_social_importador": op.razao_social_importador,
                "razao_social_exportador": op.razao_social_exportador,
            }
            for op in operacoes
        ]
    }


@app.get("/empresas/autocomplete/importadoras")
async def autocomplete_importadoras(
    q: str = Query(..., min_length=1, description="Termo de busca"),
    limit: int = Query(default=20, ge=1, le=100),
    incluir_sugestoes: bool = Query(default=True, description="Incluir empresas sugeridas do MDIC"),
    db: Session = Depends(get_db)
):
    """
    Autocomplete para empresas importadoras.
    Retorna empresas que cont√™m o termo de busca no nome.
    Se n√£o encontrar resultados, inclui empresas sugeridas do MDIC.
    """
    from sqlalchemy import func, distinct
    
    try:
        resultado = []
        
        # 1. Buscar empresas importadoras que cont√™m o termo nas opera√ß√µes
        empresas = db.query(
            OperacaoComex.razao_social_importador.label('empresa'),
            func.count(OperacaoComex.id).label('total_operacoes'),
            func.sum(OperacaoComex.valor_fob).label('valor_total')
        ).filter(
            OperacaoComex.razao_social_importador.isnot(None),
            OperacaoComex.razao_social_importador != '',
            OperacaoComex.razao_social_importador.ilike(f"%{q}%")
        ).group_by(
            OperacaoComex.razao_social_importador
        ).order_by(
            func.sum(OperacaoComex.valor_fob).desc()
        ).limit(limit).all()
        
        resultado = [
            {
                "nome": empresa,
                "total_operacoes": int(total_operacoes),
                "valor_total": float(valor_total or 0),
                "fonte": "operacoes"
            }
            for empresa, total_operacoes, valor_total in empresas
        ]
        
        # 2. Se n√£o encontrou resultados ou quer incluir sugest√µes, buscar no MDIC
        if (len(resultado) < limit and incluir_sugestoes) or len(resultado) == 0:
            try:
                from data_collector.empresas_mdic_scraper import EmpresasMDICScraper
                from data_collector.sinergia_analyzer import SinergiaAnalyzer
                
                scraper = EmpresasMDICScraper()
                empresas_mdic = await scraper.coletar_empresas()
                
                # Filtrar empresas do MDIC que s√£o importadoras e cont√™m o termo
                empresas_mdic_filtradas = [
                    emp for emp in empresas_mdic
                    if emp.get("tipo_operacao", "").lower() in ["importa√ß√£o", "importacao", ""] and
                    q.lower() in emp.get("razao_social", "").lower()
                ]
                
                # Adicionar empresas do MDIC que n√£o est√£o no resultado
                empresas_ja_adicionadas = {r["nome"].lower() for r in resultado}
                
                for emp in empresas_mdic_filtradas[:limit - len(resultado)]:
                    nome = emp.get("razao_social") or emp.get("nome_fantasia", "")
                    if nome.lower() not in empresas_ja_adicionadas:
                        resultado.append({
                            "nome": nome,
                            "total_operacoes": 0,  # N√£o temos dados de opera√ß√µes do MDIC
                            "valor_total": 0.0,
                            "fonte": "mdic",
                            "cnpj": emp.get("cnpj"),
                            "uf": emp.get("uf"),
                            "faixa_valor": emp.get("faixa_valor")
                        })
                        empresas_ja_adicionadas.add(nome.lower())
                
            except Exception as e:
                logger.debug(f"Erro ao buscar empresas MDIC para autocomplete: {e}")
        
        # 3. Se ainda n√£o tem resultados suficientes, buscar sugest√µes de sinergias
        if len(resultado) < limit and incluir_sugestoes:
            try:
                from data_collector.sinergia_analyzer import SinergiaAnalyzer
                from data_collector.cnae_analyzer import CNAEAnalyzer
                
                # Carregar CNAE se dispon√≠vel
                cnae_analyzer = None
                try:
                    arquivo_cnae = Path("C:/Users/User/Desktop/Cursor/NOVO CNAE.xlsx")
                    if arquivo_cnae.exists():
                        cnae_analyzer = CNAEAnalyzer(arquivo_cnae)
                        cnae_analyzer.carregar_cnae_excel()
                except:
                    pass
                
                analyzer = SinergiaAnalyzer(cnae_analyzer)
                
                # Buscar empresas com sinergia que s√£o importadoras
                empresas_com_sinergia = analyzer.analisar_sinergias_por_empresa(db, {}, limit * 2)
                
                # Filtrar empresas que cont√™m o termo e s√£o importadoras
                empresas_ja_adicionadas = {r["nome"].lower() for r in resultado}
                
                for emp in empresas_com_sinergia:
                    nome = emp.get("razao_social", "")
                    if (nome.lower() not in empresas_ja_adicionadas and
                        q.lower() in nome.lower() and
                        emp.get("importacoes", {}).get("total_operacoes", 0) > 0):
                        resultado.append({
                            "nome": nome,
                            "total_operacoes": emp.get("importacoes", {}).get("total_operacoes", 0),
                            "valor_total": emp.get("importacoes", {}).get("valor_total", 0.0),
                            "fonte": "sinergia",
                            "potencial_sinergia": emp.get("potencial_sinergia", 0),
                            "cnpj": emp.get("cnpj"),
                            "uf": emp.get("uf")
                        })
                        empresas_ja_adicionadas.add(nome.lower())
                        
                        if len(resultado) >= limit:
                            break
            except Exception as e:
                logger.debug(f"Erro ao buscar sugest√µes de sinergia: {e}")
        
        return resultado[:limit]
        
    except Exception as e:
        logger.error(f"Erro ao buscar importadoras: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return []


@app.get("/empresas/autocomplete/exportadoras")
async def autocomplete_exportadoras(
    q: str = Query(..., min_length=1, description="Termo de busca"),
    limit: int = Query(default=20, ge=1, le=100),
    incluir_sugestoes: bool = Query(default=True, description="Incluir empresas sugeridas do MDIC"),
    db: Session = Depends(get_db)
):
    """
    Autocomplete para empresas exportadoras.
    Retorna empresas que cont√™m o termo de busca no nome.
    Se n√£o encontrar resultados, inclui empresas sugeridas do MDIC e sinergias.
    """
    from sqlalchemy import func
    
    try:
        logger.info(f"üîç Buscando exportadoras com termo: '{q}'")
        
        resultado = []
        query_lower = q.lower() if q else ""
        
        # 1. Se tem query, buscar nas opera√ß√µes primeiro
        if q:
            empresas_query = db.query(
                OperacaoComex.razao_social_exportador,
                func.count(OperacaoComex.id).label('total_operacoes'),
                func.sum(OperacaoComex.valor_fob).label('valor_total')
            ).filter(
                OperacaoComex.razao_social_exportador.isnot(None),
                OperacaoComex.razao_social_exportador != '',
                OperacaoComex.razao_social_exportador.ilike(f"%{q}%")
            ).group_by(
                OperacaoComex.razao_social_exportador
            ).order_by(
                func.sum(OperacaoComex.valor_fob).desc()
            ).limit(limit)
            
            empresas = empresas_query.all()
            
            resultado = []
            for empresa, total_operacoes, valor_total in empresas:
                if empresa:  # Garantir que empresa n√£o √© None
                    resultado.append({
                        "nome": str(empresa),
                        "total_operacoes": int(total_operacoes) if total_operacoes else 0,
                        "valor_total": float(valor_total or 0),
                        "fonte": "operacoes"
                    })
        
        logger.info(f"‚úÖ Encontradas {len(resultado)} exportadoras nas opera√ß√µes para '{q}'")
        
        # 2. Se n√£o encontrou resultados ou query vazia, buscar no MDIC
        if (len(resultado) < limit and incluir_sugestoes) or not q:
            try:
                from data_collector.empresas_mdic_scraper import EmpresasMDICScraper
                
                scraper = EmpresasMDICScraper()
                empresas_mdic = await scraper.coletar_empresas()
                
                # Filtrar empresas do MDIC que s√£o exportadoras e cont√™m o termo
                empresas_mdic_filtradas = [
                    emp for emp in empresas_mdic
                    if emp.get("tipo_operacao", "").lower() in ["exporta√ß√£o", "exportacao", ""] and
                    q.lower() in emp.get("razao_social", "").lower()
                ]
                
                # Adicionar empresas do MDIC que n√£o est√£o no resultado
                empresas_ja_adicionadas = {r["nome"].lower() for r in resultado}
                
                for emp in empresas_mdic_filtradas[:limit - len(resultado)]:
                    nome = emp.get("razao_social") or emp.get("nome_fantasia", "")
                    if nome.lower() not in empresas_ja_adicionadas:
                        resultado.append({
                            "nome": nome,
                            "total_operacoes": 0,
                            "valor_total": 0.0,
                            "fonte": "mdic",
                            "cnpj": emp.get("cnpj"),
                            "uf": emp.get("uf"),
                            "faixa_valor": emp.get("faixa_valor")
                        })
                        empresas_ja_adicionadas.add(nome.lower())
                
            except Exception as e:
                logger.debug(f"Erro ao buscar empresas MDIC: {e}")
        
        # 3. Se ainda n√£o tem resultados suficientes, buscar sugest√µes de sinergias
        if len(resultado) < limit and incluir_sugestoes:
            try:
                from data_collector.sinergia_analyzer import SinergiaAnalyzer
                from data_collector.cnae_analyzer import CNAEAnalyzer
                
                # Carregar CNAE se dispon√≠vel
                cnae_analyzer = None
                try:
                    arquivo_cnae = Path("C:/Users/User/Desktop/Cursor/NOVO CNAE.xlsx")
                    if arquivo_cnae.exists():
                        cnae_analyzer = CNAEAnalyzer(arquivo_cnae)
                        cnae_analyzer.carregar_cnae_excel()
                except:
                    pass
                
                analyzer = SinergiaAnalyzer(cnae_analyzer)
                
                # Buscar empresas com sinergia que s√£o exportadoras
                empresas_com_sinergia = analyzer.analisar_sinergias_por_empresa(db, {}, limit * 2)
                
                # Filtrar empresas que cont√™m o termo e s√£o exportadoras
                empresas_ja_adicionadas = {r["nome"].lower() for r in resultado}
                
                for emp in empresas_com_sinergia:
                    nome = emp.get("razao_social", "")
                    if (nome.lower() not in empresas_ja_adicionadas and
                        q.lower() in nome.lower() and
                        emp.get("exportacoes", {}).get("total_operacoes", 0) > 0):
                        resultado.append({
                            "nome": nome,
                            "total_operacoes": emp.get("exportacoes", {}).get("total_operacoes", 0),
                            "valor_total": emp.get("exportacoes", {}).get("valor_total", 0.0),
                            "fonte": "sinergia",
                            "potencial_sinergia": emp.get("potencial_sinergia", 0),
                            "cnpj": emp.get("cnpj"),
                            "uf": emp.get("uf")
                        })
                        empresas_ja_adicionadas.add(nome.lower())
                        
                        if len(resultado) >= limit:
                            break
            except Exception as e:
                logger.debug(f"Erro ao buscar sugest√µes de sinergia: {e}")
        
        return resultado[:limit]
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao buscar exportadoras: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return []


@app.get("/ncm/{ncm}/analise")
async def analise_ncm(
    ncm: str,
    db: Session = Depends(get_db)
):
    """
    An√°lise detalhada de um NCM espec√≠fico.
    """
    from sqlalchemy import func
    
    # Validar NCM
    if len(ncm) != 8 or not ncm.isdigit():
        raise HTTPException(status_code=400, detail="NCM inv√°lido")
    
    # Estat√≠sticas gerais
    stats = db.query(
        func.count(OperacaoComex.id).label('total_operacoes'),
        func.sum(OperacaoComex.valor_fob).label('valor_total'),
        func.sum(OperacaoComex.peso_liquido_kg).label('peso_total'),
        func.avg(OperacaoComex.valor_fob).label('valor_medio')
    ).filter(
        OperacaoComex.ncm == ncm
    ).first()
    
    # Principais pa√≠ses
    principais_paises = db.query(
        OperacaoComex.pais_origem_destino,
        OperacaoComex.tipo_operacao,
        func.sum(OperacaoComex.valor_fob).label('valor_total')
    ).filter(
        OperacaoComex.ncm == ncm
    ).group_by(
        OperacaoComex.pais_origem_destino,
        OperacaoComex.tipo_operacao
    ).order_by(
        func.sum(OperacaoComex.valor_fob).desc()
    ).limit(10).all()
    
    # Evolu√ß√£o temporal
    evolucao = db.query(
        OperacaoComex.mes_referencia,
        OperacaoComex.tipo_operacao,
        func.sum(OperacaoComex.valor_fob).label('valor_total'),
        func.count(OperacaoComex.id).label('quantidade')
    ).filter(
        OperacaoComex.ncm == ncm
    ).group_by(
        OperacaoComex.mes_referencia,
        OperacaoComex.tipo_operacao
    ).order_by(
        OperacaoComex.mes_referencia
    ).all()
    
    return {
        "ncm": ncm,
        "estatisticas": {
            "total_operacoes": stats.total_operacoes or 0,
            "valor_total": float(stats.valor_total or 0),
            "peso_total": float(stats.peso_total or 0),
            "valor_medio": float(stats.valor_medio or 0),
        },
        "principais_paises": [
            {
                "pais": pais,
                "tipo_operacao": tipo.value,
                "valor_total": float(valor_total)
            }
            for pais, tipo, valor_total in principais_paises
        ],
        "evolucao_temporal": [
            {
                "mes": mes,
                "tipo_operacao": tipo.value,
                "valor_total": float(valor_total),
                "quantidade": quantidade
            }
            for mes, tipo, valor_total, quantidade in evolucao
        ]
    }


# Endpoints de Autentica√ß√£o (opcionais - s√≥ funcionam se m√≥dulos estiverem dispon√≠veis)
if AUTH_FUNCTIONS_AVAILABLE and AUTH_AVAILABLE:
    from fastapi import Form
    from fastapi import BackgroundTasks
    import secrets
    from datetime import timedelta
    
    @app.post("/login")
    async def login(
        username: str = Form(...),
        password: str = Form(...),
        db: Session = Depends(get_db)
    ):
        """Endpoint de login usando email."""
        try:
            logger.info(f"Tentativa de login recebida: {username}")
            
            # Truncar senha se necess√°rio (bcrypt limite: 72 bytes)
            senha_original = password
            senha_bytes_original = senha_original.encode('utf-8')
            if len(senha_bytes_original) > 72:
                senha_bytes_truncada = senha_bytes_original[:72]
                senha_final = senha_bytes_truncada.decode('utf-8', errors='ignore')
                logger.warning(f"‚ö†Ô∏è Senha truncada de {len(senha_bytes_original)} para 72 bytes")
            else:
                senha_final = senha_original
            
            # username √© o email
            user = authenticate_user(db, username, senha_final)
            
            if not user:
                logger.warning(f"Login falhou para: {username}")
                raise HTTPException(
                    status_code=401,
                    detail="Email ou senha incorretos, ou cadastro aguardando aprova√ß√£o",
                    headers={"WWW-Authenticate": "Bearer"},
                )
            
            # Atualizar √∫ltimo login
            try:
                user.ultimo_login = datetime.utcnow()
                db.commit()
                logger.info(f"‚úÖ Login bem-sucedido para: {user.email}")
            except Exception as e:
                logger.error(f"Erro ao atualizar √∫ltimo login: {e}")
                db.rollback()
            
            access_token = create_access_token(data={"sub": user.email})
            
            return {
                "access_token": access_token,
                "token_type": "bearer",
                "user": {
                    "id": user.id,
                    "email": user.email,
                    "nome_completo": user.nome_completo,
                    "nome_empresa": user.nome_empresa
                }
            }
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"‚ùå Erro inesperado no login: {e}")
            raise HTTPException(status_code=500, detail=f"Erro interno do servidor: {str(e)}")
    
    class CadastroRequest(BaseModel):
        """Schema para cadastro de usu√°rio."""
        email: str
        password: str
        nome_completo: str
        data_nascimento: Optional[date] = None
        nome_empresa: Optional[str] = None
        cpf: Optional[str] = None
        cnpj: Optional[str] = None
    
    @app.post("/register")
    async def register(
        cadastro: CadastroRequest,
        background_tasks: BackgroundTasks,
        db: Session = Depends(get_db)
    ):
        """Endpoint de registro de usu√°rio com aprova√ß√£o."""
        try:
            logger.info(f"Tentativa de cadastro recebida: {cadastro.email}")
            
            # Validar senha
            senha_valida, mensagem_erro = validate_password(cadastro.password)
            if not senha_valida:
                raise HTTPException(status_code=400, detail=mensagem_erro)
            
            # Verificar se email j√° existe
            usuario_existente = db.query(Usuario).filter(Usuario.email == cadastro.email).first()
            if usuario_existente:
                raise HTTPException(status_code=400, detail="Email j√° cadastrado")
            
            # Truncar senha antes do hash
            senha_para_hash = cadastro.password
            senha_bytes = len(senha_para_hash.encode('utf-8'))
            if senha_bytes > 72:
                senha_bytes_truncated = senha_para_hash.encode('utf-8')[:72]
                senha_para_hash = senha_bytes_truncated.decode('utf-8', errors='ignore')
                logger.warning(f"‚ö†Ô∏è Senha truncada de {senha_bytes} para 72 bytes")
            
            # Todos os cadastros precisam de aprova√ß√£o manual
            novo_usuario = Usuario(
                email=cadastro.email,
                senha_hash=get_password_hash(senha_para_hash),
                nome_completo=cadastro.nome_completo,
                data_nascimento=cadastro.data_nascimento,
                nome_empresa=cadastro.nome_empresa,
                cpf=cadastro.cpf,
                cnpj=cadastro.cnpj,
                status_aprovacao="pendente",
                ativo=0  # Inativo at√© aprova√ß√£o
            )
            db.add(novo_usuario)
            db.flush()
            
            # Criar token de aprova√ß√£o
            token_aprovacao = secrets.token_urlsafe(32)
            data_expiracao = datetime.utcnow() + timedelta(days=7)
            
            aprovacao = AprovacaoCadastro(
                usuario_id=novo_usuario.id,
                token_aprovacao=token_aprovacao,
                email_destino=cadastro.email,
                status="pendente",
                data_expiracao=data_expiracao
            )
            db.add(aprovacao)
            db.commit()
            
            logger.info(f"‚úÖ Usu√°rio criado: {cadastro.email} (ID: {novo_usuario.id})")
            
            # Enviar email em background
            if EMAIL_SERVICE_AVAILABLE:
                background_tasks.add_task(
                    enviar_email_aprovacao,
                    cadastro.email,
                    cadastro.nome_completo,
                    token_aprovacao
                )
            
            return {
                "message": "Cadastro realizado com sucesso! Aguarde aprova√ß√£o por email.",
                "email": cadastro.email,
                "aprovado": False
            }
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"‚ùå Erro inesperado no cadastro: {e}")
            raise HTTPException(status_code=500, detail=f"Erro interno do servidor: {str(e)}")
    
    class RedefinirSenhaRequest(BaseModel):
        """Schema para solicitar redefini√ß√£o de senha."""
        email: str
    
    class NovaSenhaRequest(BaseModel):
        """Schema para definir nova senha."""
        token: str
        nova_senha: str
    
    @app.post("/solicitar-redefinicao-senha")
    async def solicitar_redefinicao_senha(
        request: RedefinirSenhaRequest,
        background_tasks: BackgroundTasks,
        db: Session = Depends(get_db)
    ):
        """Endpoint para solicitar redefini√ß√£o de senha."""
        try:
            usuario = db.query(Usuario).filter(Usuario.email == request.email).first()
            if not usuario:
                # Por seguran√ßa, n√£o revelar se o email existe ou n√£o
                logger.info(f"Solicita√ß√£o de redefini√ß√£o para email n√£o encontrado: {request.email}")
                return {"message": "Se o email existir, voc√™ receber√° instru√ß√µes para redefinir a senha"}
            
            # Gerar token de redefini√ß√£o
            token_redefinicao = secrets.token_urlsafe(32)
            
            # Salvar token no banco
            try:
                usuario.token_aprovacao = token_redefinicao
                db.commit()
                logger.info(f"‚úÖ Token de redefini√ß√£o salvo para {request.email}")
            except Exception as e:
                logger.error(f"Erro ao salvar token de redefini√ß√£o: {e}")
                db.rollback()
                raise HTTPException(status_code=500, detail=f"Erro ao processar solicita√ß√£o: {str(e)}")
            
            # Log do token (em produ√ß√£o, enviar por email)
            logger.info(f"üìß Token de redefini√ß√£o gerado para {request.email}: {token_redefinicao}")
            logger.info(f"   Link: http://localhost:3000/redefinir-senha?token={token_redefinicao}")
            
            return {"message": "Se o email existir, voc√™ receber√° instru√ß√µes para redefinir a senha"}
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Erro ao solicitar redefini√ß√£o: {e}")
            raise HTTPException(status_code=500, detail="Erro ao processar solicita√ß√£o")
    
    @app.post("/redefinir-senha")
    async def redefinir_senha(
        request: NovaSenhaRequest,
        db: Session = Depends(get_db)
    ):
        """Endpoint para redefinir senha usando token."""
        try:
            # Validar nova senha
            senha_valida, mensagem_erro = validate_password(request.nova_senha)
            if not senha_valida:
                raise HTTPException(status_code=400, detail=mensagem_erro)
            
            # Buscar usu√°rio pelo token
            usuario = db.query(Usuario).filter(Usuario.token_aprovacao == request.token).first()
            if not usuario:
                raise HTTPException(status_code=400, detail="Token inv√°lido ou expirado")
            
            # Truncar senha antes de criar hash
            senha_para_hash = request.nova_senha
            senha_bytes = len(senha_para_hash.encode('utf-8'))
            if senha_bytes > 72:
                senha_bytes_truncated = senha_para_hash.encode('utf-8')[:72]
                senha_para_hash = senha_bytes_truncated.decode('utf-8', errors='ignore')
                logger.warning(f"‚ö†Ô∏è Senha truncada de {senha_bytes} para 72 bytes na redefini√ß√£o")
            
            # Atualizar senha
            usuario.senha_hash = get_password_hash(senha_para_hash)
            usuario.token_aprovacao = None  # Limpar token ap√≥s uso
            db.commit()
            
            logger.info(f"‚úÖ Senha redefinida para: {usuario.email}")
            return {"message": "Senha redefinida com sucesso"}
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Erro ao redefinir senha: {e}")
            raise HTTPException(status_code=500, detail="Erro ao redefinir senha")
    
    class AprovarCadastroRequest(BaseModel):
        """Schema para aprovar cadastro."""
        token: str
    
    @app.post("/aprovar-cadastro")
    async def aprovar_cadastro(
        request: AprovarCadastroRequest,
        background_tasks: BackgroundTasks,
        db: Session = Depends(get_db)
    ):
        """Endpoint para aprovar cadastro usando token."""
        try:
            # Buscar aprova√ß√£o pelo token
            aprovacao = db.query(AprovacaoCadastro).filter(
                AprovacaoCadastro.token_aprovacao == request.token,
                AprovacaoCadastro.status == "pendente"
            ).first()
            
            if not aprovacao:
                raise HTTPException(status_code=400, detail="Token inv√°lido ou cadastro j√° processado")
            
            # Verificar se token n√£o expirou
            if aprovacao.data_expiracao < datetime.utcnow():
                raise HTTPException(status_code=400, detail="Token expirado")
            
            # Buscar usu√°rio
            usuario = db.query(Usuario).filter(Usuario.id == aprovacao.usuario_id).first()
            if not usuario:
                raise HTTPException(status_code=404, detail="Usu√°rio n√£o encontrado")
            
            # Aprovar usu√°rio
            usuario.status_aprovacao = "aprovado"
            usuario.ativo = 1
            aprovacao.status = "aprovado"
            aprovacao.data_aprovacao = datetime.utcnow()
            db.commit()
            
            logger.info(f"‚úÖ Cadastro aprovado para: {usuario.email}")
            
            # Enviar email de confirma√ß√£o para o usu√°rio
            if EMAIL_SERVICE_AVAILABLE:
                background_tasks.add_task(
                    enviar_email_cadastro_aprovado,
                    usuario.email,
                    usuario.nome_completo
                )
            
            return {
                "message": "Cadastro aprovado com sucesso!",
                "email": usuario.email,
                "nome": usuario.nome_completo
            }
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Erro ao aprovar cadastro: {e}")
            raise HTTPException(status_code=500, detail="Erro ao aprovar cadastro")
    
    @app.get("/cadastros-pendentes")
    async def listar_cadastros_pendentes(
        db: Session = Depends(get_db)
    ):
        """Lista todos os cadastros pendentes de aprova√ß√£o."""
        try:
            cadastros = db.query(Usuario).filter(
                Usuario.status_aprovacao == "pendente"
            ).all()
            
            cadastros_list = []
            for c in cadastros:
                # Buscar token de aprova√ß√£o
                aprovacao = db.query(AprovacaoCadastro).filter(
                    AprovacaoCadastro.usuario_id == c.id,
                    AprovacaoCadastro.status == "pendente"
                ).first()
                
                cadastros_list.append({
                    "id": c.id,
                    "email": c.email,
                    "nome_completo": c.nome_completo,
                    "nome_empresa": c.nome_empresa,
                    "cpf": c.cpf,
                    "cnpj": c.cnpj,
                    "data_criacao": c.data_criacao.isoformat() if c.data_criacao else None,
                    "token_aprovacao": aprovacao.token_aprovacao if aprovacao else None,
                    "link_aprovacao": f"http://localhost:8000/docs#/default/aprovar_cadastro_aprovar_cadastro_post" if aprovacao else None
                })
            
            return {
                "total": len(cadastros_list),
                "cadastros": cadastros_list
            }
        except Exception as e:
            logger.error(f"Erro ao listar cadastros pendentes: {e}")
            import traceback
            logger.error(traceback.format_exc())
            raise HTTPException(status_code=500, detail="Erro ao listar cadastros pendentes")
    
    @app.post("/criar-usuario-teste")
    async def criar_usuario_teste(
        email: str = Form(...),
        senha: str = Form(...),
        nome_completo: str = Form(...),
        db: Session = Depends(get_db)
    ):
        """
        Endpoint para criar usu√°rio j√° aprovado (apenas para desenvolvimento/teste).
        ATEN√á√ÉO: Em produ√ß√£o, considere proteger este endpoint com autentica√ß√£o admin.
        """
        try:
            # Verificar se usu√°rio j√° existe
            usuario_existente = db.query(Usuario).filter(Usuario.email == email).first()
            
            if usuario_existente:
                # Atualizar usu√°rio existente
                usuario_existente.senha_hash = get_password_hash(senha)
                usuario_existente.nome_completo = nome_completo
                usuario_existente.status_aprovacao = "aprovado"
                usuario_existente.ativo = 1
                usuario_existente.token_aprovacao = None
                
                db.commit()
                logger.info(f"‚úÖ Usu√°rio {email} atualizado e aprovado")
                return {
                    "message": "Usu√°rio atualizado e aprovado com sucesso",
                    "email": email,
                    "status": "aprovado"
                }
            
            # Criar novo usu√°rio
            senha_hash = get_password_hash(senha)
            
            novo_usuario = Usuario(
                email=email,
                senha_hash=senha_hash,
                nome_completo=nome_completo,
                status_aprovacao="aprovado",
                ativo=1,
                token_aprovacao=None,
                data_criacao=datetime.utcnow()
            )
            
            db.add(novo_usuario)
            db.commit()
            
            logger.info(f"‚úÖ Usu√°rio {email} criado e aprovado")
            return {
                "message": "Usu√°rio criado e aprovado com sucesso",
                "email": email,
                "status": "aprovado"
            }
            
        except Exception as e:
            db.rollback()
            logger.error(f"Erro ao criar usu√°rio teste: {e}")
            raise HTTPException(status_code=500, detail=f"Erro ao criar usu√°rio: {str(e)}")
else:
    # Endpoints stub quando autentica√ß√£o n√£o est√° dispon√≠vel
    @app.post("/login")
    async def login_stub():
        """Endpoint de login n√£o dispon√≠vel - m√≥dulos de autentica√ß√£o n√£o instalados."""
        raise HTTPException(
            status_code=501,
            detail="Autentica√ß√£o n√£o dispon√≠vel. M√≥dulos de autentica√ß√£o n√£o est√£o instalados."
        )
    
    @app.post("/register")
    async def register_stub():
        """Endpoint de registro n√£o dispon√≠vel - m√≥dulos de autentica√ß√£o n√£o instalados."""
        raise HTTPException(
            status_code=501,
            detail="Cadastro n√£o dispon√≠vel. M√≥dulos de autentica√ß√£o n√£o est√£o instalados."
        )


# Endpoints para cruzamento de dados com empresas do MDIC
try:
    from data_collector.cruzamento_dados import CruzamentoDados
    from data_collector.empresas_mdic_scraper import EmpresasMDICScraper
    CRUZAMENTO_AVAILABLE = True
except ImportError:
    CRUZAMENTO_AVAILABLE = False
    logger.warning("M√≥dulos de cruzamento n√£o dispon√≠veis")

# Endpoints para an√°lise de sinergias e CNAE
try:
    from data_collector.sinergia_analyzer import SinergiaAnalyzer
    from data_collector.cnae_analyzer import CNAEAnalyzer
    SINERGIA_AVAILABLE = True
except ImportError:
    SINERGIA_AVAILABLE = False
    logger.warning("M√≥dulos de sinergia n√£o dispon√≠veis")


@app.post("/coletar-empresas-mdic")
async def coletar_empresas_mdic(
    ano: Optional[int] = Query(None, description="Ano espec√≠fico (None = ano atual)"),
    db: Session = Depends(get_db)
):
    """
    Coleta lista de empresas exportadoras e importadoras do MDIC.
    Esta lista cont√©m CNPJ e nome das empresas, mas sem detalhamento por NCM.
    """
    if not CRUZAMENTO_AVAILABLE:
        raise HTTPException(status_code=501, detail="M√≥dulo de cruzamento n√£o dispon√≠vel")
    
    try:
        scraper = EmpresasMDICScraper()
        empresas = await scraper.coletar_empresas(ano)
        
        return {
            "success": True,
            "message": f"Coletadas {len(empresas)} empresas do MDIC",
            "total_empresas": len(empresas),
            "ano": ano or datetime.now().year,
            "empresas": empresas[:100]  # Retornar primeiras 100 como exemplo
        }
    except Exception as e:
        logger.error(f"Erro ao coletar empresas do MDIC: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erro ao coletar empresas: {str(e)}")


class CruzamentoFiltros(BaseModel):
    """Filtros para cruzamento de dados."""
    ncm: Optional[str] = None
    tipo_operacao: Optional[str] = None
    uf: Optional[str] = None
    limite: int = 1000


@app.post("/cruzar-dados-empresas")
async def cruzar_dados_empresas(
    filtros: CruzamentoFiltros,
    db: Session = Depends(get_db)
):
    """
    Cruza dados de opera√ß√µes com lista de empresas do MDIC.
    Tenta identificar empresas por CNPJ ou raz√£o social.
    """
    if not CRUZAMENTO_AVAILABLE:
        raise HTTPException(status_code=501, detail="M√≥dulo de cruzamento n√£o dispon√≠vel")
    
    try:
        cruzamento = CruzamentoDados()
        
        filtros_dict = {}
        if filtros.ncm:
            filtros_dict["ncm"] = filtros.ncm
        if filtros.tipo_operacao:
            filtros_dict["tipo_operacao"] = filtros.tipo_operacao
        if filtros.uf:
            filtros_dict["uf"] = filtros.uf
        
        resultados = await cruzamento.cruzar_operacoes_bulk(
            db,
            filtros=filtros_dict if filtros_dict else None,
            limite=filtros.limite
        )
        
        estatisticas = cruzamento.estatisticas_cruzamento(resultados)
        
        return {
            "success": True,
            "message": f"Cruzamento conclu√≠do: {estatisticas['operacoes_identificadas']}/{estatisticas['total_operacoes']} opera√ß√µes identificadas",
            "estatisticas": estatisticas,
            "resultados": resultados[:100]  # Retornar primeiras 100 como exemplo
        }
    except Exception as e:
        logger.error(f"Erro ao cruzar dados: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erro ao cruzar dados: {str(e)}")


@app.get("/estatisticas-cruzamento")
async def estatisticas_cruzamento(
    db: Session = Depends(get_db)
):
    """
    Retorna estat√≠sticas sobre cruzamento de dados.
    """
    if not CRUZAMENTO_AVAILABLE:
        raise HTTPException(status_code=501, detail="M√≥dulo de cruzamento n√£o dispon√≠vel")
    
    try:
        # Contar opera√ß√µes com CNPJ
        from sqlalchemy import func, or_
        
        total_operacoes = db.query(func.count(OperacaoComex.id)).scalar() or 0
        
        operacoes_com_cnpj = db.query(func.count(OperacaoComex.id)).filter(
            or_(
                OperacaoComex.cnpj_importador.isnot(None),
                OperacaoComex.cnpj_exportador.isnot(None)
            )
        ).scalar() or 0
        
        operacoes_com_razao_social = db.query(func.count(OperacaoComex.id)).filter(
            or_(
                OperacaoComex.razao_social_importador.isnot(None),
                OperacaoComex.razao_social_exportador.isnot(None)
            )
        ).scalar() or 0
        
        return {
            "total_operacoes": total_operacoes,
            "operacoes_com_cnpj": operacoes_com_cnpj,
            "operacoes_com_razao_social": operacoes_com_razao_social,
            "taxa_cnpj": (operacoes_com_cnpj / total_operacoes * 100) if total_operacoes > 0 else 0,
            "taxa_razao_social": (operacoes_com_razao_social / total_operacoes * 100) if total_operacoes > 0 else 0,
            "nota": "Dados p√∫blicos s√£o anonimizados. CNPJ/raz√£o social podem n√£o estar dispon√≠veis em todas as opera√ß√µes."
        }
    except Exception as e:
        logger.error(f"Erro ao calcular estat√≠sticas: {e}")
        raise HTTPException(status_code=500, detail=f"Erro ao calcular estat√≠sticas: {str(e)}")


@app.post("/carregar-cnae")
async def carregar_cnae(
    arquivo_path: Optional[str] = Query(None, description="Caminho do arquivo Excel CNAE")
):
    """
    Carrega arquivo Excel com classifica√ß√£o CNAE.
    """
    if not SINERGIA_AVAILABLE:
        raise HTTPException(status_code=501, detail="M√≥dulo de sinergia n√£o dispon√≠vel")
    
    try:
        from pathlib import Path
        
        if arquivo_path:
            arquivo = Path(arquivo_path)
        else:
            # Tentar caminho padr√£o
            arquivo = Path("C:/Users/User/Desktop/Cursor/NOVO CNAE.xlsx")
        
        analyzer = CNAEAnalyzer(arquivo)
        sucesso = analyzer.carregar_cnae_excel()
        
        if sucesso:
            stats = analyzer.estatisticas()
            return {
                "success": True,
                "message": f"CNAE carregado com sucesso",
                "estatisticas": stats
            }
        else:
            raise HTTPException(status_code=400, detail="N√£o foi poss√≠vel carregar arquivo CNAE")
    except Exception as e:
        logger.error(f"Erro ao carregar CNAE: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erro ao carregar CNAE: {str(e)}")


@app.get("/analisar-sinergias-estado")
async def analisar_sinergias_estado(
    uf: Optional[str] = Query(None, description="UF espec√≠fica (None = todos)"),
    db: Session = Depends(get_db)
):
    """
    Analisa sinergias de importa√ß√£o/exporta√ß√£o por estado.
    """
    if not SINERGIA_AVAILABLE:
        raise HTTPException(status_code=501, detail="M√≥dulo de sinergia n√£o dispon√≠vel")
    
    try:
        analyzer = SinergiaAnalyzer()
        resultado = analyzer.analisar_sinergias_por_estado(db, uf)
        return resultado
    except Exception as e:
        logger.error(f"Erro ao analisar sinergias: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erro ao analisar sinergias: {str(e)}")


@app.post("/analisar-sinergias-empresas")
async def analisar_sinergias_empresas(
    limite: int = Query(100, description="Limite de empresas a analisar"),
    ano: Optional[int] = Query(None, description="Ano para coletar empresas do MDIC"),
    db: Session = Depends(get_db)
):
    """
    Analisa sinergias por empresa, integrando com CNAE.
    """
    if not SINERGIA_AVAILABLE or not CRUZAMENTO_AVAILABLE:
        raise HTTPException(status_code=501, detail="M√≥dulos necess√°rios n√£o dispon√≠veis")
    
    try:
        # Carregar empresas do MDIC
        scraper = EmpresasMDICScraper()
        empresas_lista = await scraper.coletar_empresas(ano)
        
        # Criar √≠ndice por CNPJ
        empresas_mdic = {}
        for empresa in empresas_lista:
            cnpj = empresa.get("cnpj")
            if cnpj:
                empresas_mdic[cnpj] = empresa
        
        # Carregar CNAE se dispon√≠vel
        cnae_analyzer = None
        try:
            arquivo_cnae = Path("C:/Users/User/Desktop/Cursor/NOVO CNAE.xlsx")
            if arquivo_cnae.exists():
                cnae_analyzer = CNAEAnalyzer(arquivo_cnae)
                cnae_analyzer.carregar_cnae_excel()
        except Exception as e:
            logger.warning(f"N√£o foi poss√≠vel carregar CNAE: {e}")
        
        # Analisar sinergias
        analyzer = SinergiaAnalyzer(cnae_analyzer)
        resultados = analyzer.analisar_sinergias_por_empresa(db, empresas_mdic, limite)
        
        return {
            "success": True,
            "message": f"An√°lise de sinergias conclu√≠da para {len(resultados)} empresas",
            "total_empresas_mdic": len(empresas_mdic),
            "empresas_analisadas": len(resultados),
            "cnae_carregado": cnae_analyzer is not None,
            "resultados": resultados
        }
    except Exception as e:
        logger.error(f"Erro ao analisar sinergias de empresas: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erro ao analisar sinergias: {str(e)}")


@app.get("/sugestoes-empresa/{cnpj}")
async def sugestoes_empresa(
    cnpj: str,
    db: Session = Depends(get_db)
):
    """
    Gera sugest√µes de importa√ß√£o/exporta√ß√£o para uma empresa espec√≠fica.
    """
    if not SINERGIA_AVAILABLE:
        raise HTTPException(status_code=501, detail="M√≥dulo de sinergia n√£o dispon√≠vel")
    
    try:
        # Buscar empresa no MDIC
        scraper = EmpresasMDICScraper()
        empresas_lista = await scraper.coletar_empresas()
        
        empresa_mdic = None
        cnpj_limpo = cnpj.replace('.', '').replace('/', '').replace('-', '')
        for empresa in empresas_lista:
            if empresa.get("cnpj") == cnpj_limpo:
                empresa_mdic = empresa
                break
        
        if not empresa_mdic:
            raise HTTPException(status_code=404, detail="Empresa n√£o encontrada no MDIC")
        
        # Carregar CNAE
        cnae_analyzer = None
        try:
            arquivo_cnae = Path("C:/Users/User/Desktop/Cursor/NOVO CNAE.xlsx")
            if arquivo_cnae.exists():
                cnae_analyzer = CNAEAnalyzer(arquivo_cnae)
                cnae_analyzer.carregar_cnae_excel()
        except Exception as e:
            logger.warning(f"N√£o foi poss√≠vel carregar CNAE: {e}")
        
        # Analisar empresa
        analyzer = SinergiaAnalyzer(cnae_analyzer)
        sinergia = analyzer._analisar_empresa_individual(
            db,
            cnpj_limpo,
            empresa_mdic,
            empresa_mdic.get("uf")
        )
        
        if not sinergia:
            raise HTTPException(status_code=404, detail="N√£o foi poss√≠vel analisar empresa")
        
        return {
            "success": True,
            "empresa": sinergia,
            "sugestoes": {
                "importacao": sinergia.get("sugestao", ""),
                "exportacao": sinergia.get("sugestao", ""),
                "cnae": sinergia.get("cnae"),
                "classificacao_cnae": sinergia.get("classificacao_cnae")
            }
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erro ao gerar sugest√µes: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erro ao gerar sugest√µes: {str(e)}")


@app.post("/atualizar-dados-completos")
async def atualizar_dados_completos():
    """
    Executa atualiza√ß√£o completa de todos os dados (empresas MDIC, relacionamentos, sinergias).
    √ötil para atualiza√ß√£o manual ou via scheduler.
    """
    try:
        from utils.data_updater import DataUpdater
        
        updater = DataUpdater()
        resultado = await updater.atualizar_completo()
        
        return resultado
    except Exception as e:
        logger.error(f"Erro na atualiza√ß√£o completa: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erro na atualiza√ß√£o: {str(e)}")


@app.get("/dashboard/sinergias-estado")
async def dashboard_sinergias_estado(
    uf: Optional[str] = Query(None),
    db: Session = Depends(get_db)
):
    """
    Endpoint otimizado para dashboard - sinergias por estado.
    """
    if not SINERGIA_AVAILABLE:
        raise HTTPException(status_code=501, detail="M√≥dulo de sinergia n√£o dispon√≠vel")
    
    try:
        analyzer = SinergiaAnalyzer()
        resultado = analyzer.analisar_sinergias_por_estado(db, uf)
        return resultado
    except Exception as e:
        logger.error(f"Erro ao buscar sinergias: {e}")
        raise HTTPException(status_code=500, detail=f"Erro ao buscar sinergias: {str(e)}")


@app.get("/dashboard/sugestoes-empresas")
async def dashboard_sugestoes_empresas(
    limite: int = Query(20, description="N√∫mero de sugest√µes"),
    tipo: Optional[str] = Query(None, description="Tipo: 'importacao', 'exportacao', ou None para ambos"),
    uf: Optional[str] = Query(None, description="Filtrar por UF"),
    db: Session = Depends(get_db)
):
    """
    Endpoint otimizado para dashboard - sugest√µes de empresas.
    Retorna empresas com maior potencial de sinergia.
    """
    if not SINERGIA_AVAILABLE or not CRUZAMENTO_AVAILABLE:
        raise HTTPException(status_code=501, detail="M√≥dulos necess√°rios n√£o dispon√≠veis")
    
    try:
        # Carregar empresas
        scraper = EmpresasMDICScraper()
        empresas_lista = await scraper.coletar_empresas()
        empresas_mdic = {}
        for empresa in empresas_lista:
            cnpj = empresa.get("cnpj")
            if cnpj:
                empresas_mdic[cnpj] = empresa
        
        # Carregar CNAE
        cnae_analyzer = None
        try:
            arquivo_cnae = Path("C:/Users/User/Desktop/Cursor/NOVO CNAE.xlsx")
            if arquivo_cnae.exists():
                cnae_analyzer = CNAEAnalyzer(arquivo_cnae)
                cnae_analyzer.carregar_cnae_excel()
        except Exception as e:
            logger.warning(f"N√£o foi poss√≠vel carregar CNAE: {e}")
        
        # Analisar sinergias
        analyzer = SinergiaAnalyzer(cnae_analyzer)
        resultados = analyzer.analisar_sinergias_por_empresa(db, empresas_mdic, limite * 2)
        
        # Filtrar por tipo se especificado
        if tipo == "importacao":
            resultados = [r for r in resultados if r["importacoes"]["total_operacoes"] > 0 and r["exportacoes"]["total_operacoes"] == 0]
        elif tipo == "exportacao":
            resultados = [r for r in resultados if r["exportacoes"]["total_operacoes"] > 0 and r["importacoes"]["total_operacoes"] == 0]
        
        # Filtrar por UF se especificado
        if uf:
            resultados = [r for r in resultados if r.get("uf") == uf]
        
        # Ordenar por potencial e limitar
        resultados.sort(key=lambda x: x.get("potencial_sinergia", 0), reverse=True)
        resultados = resultados[:limite]
        
        return {
            "success": True,
            "total": len(resultados),
            "sugestoes": resultados
        }
    except Exception as e:
        logger.error(f"Erro ao buscar sugest√µes: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erro ao buscar sugest√µes: {str(e)}")


if __name__ == "__main__":
    from loguru import logger
    
    logger.info("Iniciando servidor FastAPI...")
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=settings.debug,
        log_level=settings.log_level.lower()
    )

