"""
AplicaÃ§Ã£o principal FastAPI.
"""
from fastapi import FastAPI, Depends, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy.orm import Session
from sqlalchemy import text
from typing import Optional, List
from datetime import date, datetime
from pydantic import BaseModel
from pathlib import Path
import uvicorn

from loguru import logger

from config import settings
from database import get_db, init_db
from database.models import (
    OperacaoComex, TipoOperacao, ViaTransporte,
    ComercioExterior, Empresa, CNAEHierarquia, EmpresasRecomendadas
)
from data_collector import DataCollector

# Import opcional do router de exportaÃ§Ã£o
try:
    from api.export import router as export_router
    EXPORT_ROUTER_AVAILABLE = True
except ImportError:
    EXPORT_ROUTER_AVAILABLE = False
    logger.warning("Router de exportaÃ§Ã£o nÃ£o disponÃ­vel")

# Imports opcionais para funcionalidades de autenticaÃ§Ã£o
try:
    from database.models import Usuario, AprovacaoCadastro
    AUTH_AVAILABLE = True
except ImportError:
    AUTH_AVAILABLE = False
    logger.warning("Modelos de autenticaÃ§Ã£o nÃ£o disponÃ­veis")

try:
    from auth import authenticate_user, create_access_token, get_current_user, get_password_hash, validate_password
    AUTH_FUNCTIONS_AVAILABLE = True
except ImportError:
    AUTH_FUNCTIONS_AVAILABLE = False
    logger.warning("FunÃ§Ãµes de autenticaÃ§Ã£o nÃ£o disponÃ­veis")

try:
    from services.email_service import enviar_email_aprovacao, enviar_email_cadastro_aprovado
    EMAIL_SERVICE_AVAILABLE = True
except ImportError:
    EMAIL_SERVICE_AVAILABLE = False
    logger.warning("ServiÃ§o de email nÃ£o disponÃ­vel")

# Inicializar app FastAPI
app = FastAPI(
    title="Comex Analyzer API",
    description="API para anÃ¡lise de dados do comÃ©rcio exterior brasileiro",
    version="1.0.0"
)

# Configurar CORS para permitir requisiÃ§Ãµes do frontend Electron
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Em produÃ§Ã£o, especificar origem do Electron
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Incluir routers
if EXPORT_ROUTER_AVAILABLE:
    app.include_router(export_router)

# Router de anÃ¡lise de empresas
try:
    from api.analise_empresas import router as analise_router
    app.include_router(analise_router)
    logger.info("âœ… Router de anÃ¡lise de empresas incluÃ­do")
except ImportError as e:
    logger.warning(f"Router de anÃ¡lise de empresas nÃ£o disponÃ­vel: {e}")

# Router de coleta da Base dos Dados
try:
    from api.coletar_base_dados import router as coletar_router
    app.include_router(coletar_router)
    logger.info("âœ… Router de coleta Base dos Dados incluÃ­do")
except ImportError as e:
    logger.warning(f"Router de coleta Base dos Dados nÃ£o disponÃ­vel: {e}")


# Inicializar banco de dados na startup
@app.on_event("startup")
async def startup_event():
    """Inicializa o banco de dados na startup."""
    try:
        # Executar migrations do Alembic antes de inicializar
        import subprocess
        import sys
        logger.info("ðŸ”„ Executando migrations do Alembic...")
        try:
            result = subprocess.run(
                [sys.executable, "-m", "alembic", "upgrade", "head"],
                cwd=Path(__file__).parent,
                capture_output=True,
                text=True,
                timeout=60
            )
            if result.returncode == 0:
                logger.info("âœ… Migrations executadas com sucesso")
            else:
                logger.warning(f"âš ï¸ Migration retornou cÃ³digo {result.returncode}: {result.stderr}")
        except subprocess.TimeoutExpired:
            logger.warning("âš ï¸ Migration timeout, continuando...")
        except Exception as migration_error:
            logger.warning(f"âš ï¸ Erro ao executar migrations: {migration_error}, continuando...")
        
        # Inicializar banco (cria tabelas se nÃ£o existirem)
        init_db()
        logger.info("âœ… Banco de dados inicializado")
    except Exception as e:
        logger.error(f"Erro ao inicializar banco de dados: {e}")
        # NÃ£o interrompe a aplicaÃ§Ã£o, mas loga o erro
    
    # Iniciar scheduler para atualizaÃ§Ã£o diÃ¡ria
    try:
        from utils.scheduler import DataScheduler
        scheduler = DataScheduler()
        scheduler.start()
        logger.info("Scheduler de atualizaÃ§Ã£o diÃ¡ria iniciado")
        
        # Executar atualizaÃ§Ã£o inicial de empresas e sinergias em background
        async def atualizacao_inicial():
            try:
                from utils.data_updater import DataUpdater
                updater = DataUpdater()
                logger.info("Iniciando atualizaÃ§Ã£o inicial de empresas MDIC e sinergias...")
                await updater.atualizar_empresas_mdic()
                await updater.atualizar_relacionamentos(limite=500)  # Limite menor na inicializaÃ§Ã£o
                await updater.atualizar_sinergias(limite_empresas=50)  # Limite menor na inicializaÃ§Ã£o
                logger.info("âœ… AtualizaÃ§Ã£o inicial concluÃ­da")
            except Exception as e:
                logger.warning(f"AtualizaÃ§Ã£o inicial nÃ£o executada: {e}")
        
        # Executar apÃ³s 30 segundos (dar tempo para o servidor inicializar)
        import asyncio
        import threading
        def run_initial_update():
            import time
            time.sleep(30)
            asyncio.run(atualizacao_inicial())
        
        update_thread = threading.Thread(target=run_initial_update, daemon=True)
        update_thread.start()
        
    except Exception as e:
        logger.warning(f"NÃ£o foi possÃ­vel iniciar scheduler: {e}")
        # NÃ£o interrompe a aplicaÃ§Ã£o se o scheduler falhar


# Schemas Pydantic
class OperacaoResponse(BaseModel):
    """Schema de resposta para operaÃ§Ã£o."""
    id: int
    ncm: str
    descricao_produto: str
    tipo_operacao: str
    pais_origem_destino: str
    uf: str
    valor_fob: float
    data_operacao: date
    
    class Config:
        from_attributes = True


class DashboardStats(BaseModel):
    """EstatÃ­sticas do dashboard."""
    volume_importacoes: float
    volume_exportacoes: float
    valor_total_usd: float
    valor_total_importacoes: Optional[float] = None  # Valor total de importaÃ§Ãµes
    valor_total_exportacoes: Optional[float] = None  # Valor total de exportaÃ§Ãµes
    principais_ncms: List[dict]
    principais_paises: List[dict]
    registros_por_mes: dict
    valores_por_mes: Optional[dict] = None  # Valores FOB por mÃªs
    pesos_por_mes: Optional[dict] = None  # Pesos por mÃªs


class BuscaFiltros(BaseModel):
    """Filtros de busca."""
    ncms: Optional[List[str]] = None  # Lista de NCMs
    ncm: Optional[str] = None  # Mantido para compatibilidade
    data_inicio: Optional[date] = None
    data_fim: Optional[date] = None
    tipo_operacao: Optional[str] = None
    pais: Optional[str] = None
    uf: Optional[str] = None
    via_transporte: Optional[str] = None
    valor_fob_min: Optional[float] = None
    valor_fob_max: Optional[float] = None
    peso_min: Optional[float] = None
    peso_max: Optional[float] = None
    empresa_importadora: Optional[str] = None
    empresa_exportadora: Optional[str] = None
    page: int = 1
    page_size: int = 100


# Endpoints
@app.get("/")
async def root():
    """Endpoint raiz."""
    return {
        "message": "Comex Analyzer API",
        "version": "1.0.0",
        "status": "online"
    }


@app.get("/health")
async def health_check(db: Session = Depends(get_db)):
    """Verifica saÃºde da API."""
    try:
        # Testar conexÃ£o com banco
        db.execute(text("SELECT 1"))
        db.commit()
        return {"status": "healthy", "database": "connected"}
    except Exception as e:
        logger.error(f"Health check error: {e}")
        return {"status": "unhealthy", "error": str(e)}


@app.get("/validar-sistema")
async def validar_sistema_completo(db: Session = Depends(get_db)):
    """
    ValidaÃ§Ã£o completa do sistema.
    Verifica:
    - ConexÃ£o com BigQuery
    - Dados no banco de dados PostgreSQL
    - Arquivos CSV disponÃ­veis
    - Relacionamentos entre bases
    """
    from sqlalchemy import func
    from database.models import (
        OperacaoComex, Empresa, EmpresasRecomendadas,
        ComercioExterior, CNAEHierarquia
    )
    from pathlib import Path
    import os
    import json
    
    resultados = {
        "data_validacao": datetime.now().isoformat(),
        "bigquery": {},
        "banco_dados": {},
        "arquivos_csv": {},
        "relacionamentos": {},
        "resumo": {}
    }
    
    try:
        # 1. Validar BigQuery
        logger.info("ðŸ” Validando BigQuery...")
        bigquery_result = {"conectado": False, "credenciais_configuradas": False, "teste_query": False, "erro": None}
        
        creds_env = os.getenv("GOOGLE_APPLICATION_CREDENTIALS") or os.getenv("GOOGLE_APPLICATION_CREDENTIALS_JSON")
        if creds_env:
            bigquery_result["credenciais_configuradas"] = True
            if creds_env.startswith('{'):
                try:
                    json.loads(creds_env)
                    bigquery_result["credenciais_validas"] = True
                except:
                    bigquery_result["credenciais_validas"] = False
        
        try:
            from google.cloud import bigquery
            if creds_env and creds_env.startswith('{'):
                try:
                    creds_dict = json.loads(creds_env)
                    from google.oauth2 import service_account
                    credentials = service_account.Credentials.from_service_account_info(creds_dict)
                    client = bigquery.Client(credentials=credentials)
                except:
                    client = bigquery.Client()
            else:
                client = bigquery.Client()
            
            bigquery_result["conectado"] = True
            query_job = client.query("SELECT 1 as test")
            query_job.result()
            bigquery_result["teste_query"] = True
        except ImportError:
            bigquery_result["erro"] = "Biblioteca google-cloud-bigquery nÃ£o instalada"
        except Exception as e:
            bigquery_result["erro"] = str(e)
        
        resultados["bigquery"] = bigquery_result
        
        # 2. Validar Banco de Dados
        logger.info("ðŸ” Validando banco de dados...")
        banco_result = {"conectado": False, "tabelas": {}, "total_registros": {}}
        
        try:
            db.execute(text("SELECT 1"))
            banco_result["conectado"] = True
            
            tabelas_verificar = [
                ("operacoes_comex", OperacaoComex),
                ("empresas", Empresa),
                ("empresas_recomendadas", EmpresasRecomendadas),
                ("comercio_exterior", ComercioExterior),
                ("cnae_hierarquia", CNAEHierarquia)
            ]
            
            for nome_tabela, modelo in tabelas_verificar:
                try:
                    count = db.query(func.count(modelo.id)).scalar()
                    banco_result["tabelas"][nome_tabela] = {"existe": True, "total_registros": count}
                    banco_result["total_registros"][nome_tabela] = count
                except Exception as e:
                    banco_result["tabelas"][nome_tabela] = {"existe": False, "erro": str(e)}
            
            # Detalhes de operacoes_comex
            if banco_result["total_registros"].get("operacoes_comex", 0) > 0:
                importacao = db.query(func.count(OperacaoComex.id)).filter(
                    OperacaoComex.tipo_operacao == "ImportaÃ§Ã£o"
                ).scalar()
                exportacao = db.query(func.count(OperacaoComex.id)).filter(
                    OperacaoComex.tipo_operacao == "ExportaÃ§Ã£o"
                ).scalar()
                
                banco_result["operacoes_detalhes"] = {
                    "importacao": importacao,
                    "exportacao": exportacao
                }
                
                cnpjs_importadores = db.query(func.count(func.distinct(OperacaoComex.cnpj_importador))).scalar()
                cnpjs_exportadores = db.query(func.count(func.distinct(OperacaoComex.cnpj_exportador))).scalar()
                
                banco_result["cnpjs_unicos"] = {
                    "importadores": cnpjs_importadores,
                    "exportadores": cnpjs_exportadores
                }
        except Exception as e:
            banco_result["erro"] = str(e)
        
        resultados["banco_dados"] = banco_result
        
        # 3. Validar Arquivos CSV
        logger.info("ðŸ” Validando arquivos CSV...")
        csv_result = {"diretorio_existe": False, "arquivos_encontrados": [], "total_arquivos": 0}
        
        try:
            base_dir = Path(__file__).parent.parent
            csv_dir = base_dir / "comex_data" / "comexstat_csv"
            csv_downloads_dir = base_dir / "comex_data" / "csv_downloads"
            
            if csv_dir.exists():
                csv_result["diretorio_existe"] = True
                arquivos_csv = list(csv_dir.glob("*.csv")) + list(csv_dir.glob("*.xlsx"))
                csv_result["total_arquivos"] = len(arquivos_csv)
                
                for arquivo in arquivos_csv[:10]:  # Limitar a 10 para nÃ£o sobrecarregar resposta
                    tamanho = arquivo.stat().st_size
                    csv_result["arquivos_encontrados"].append({
                        "nome": arquivo.name,
                        "tamanho": tamanho
                    })
            
            if csv_downloads_dir.exists():
                arquivos_downloads = list(csv_downloads_dir.glob("*.csv"))
                importacoes = [f for f in arquivos_downloads if "importacao" in f.name]
                exportacoes = [f for f in arquivos_downloads if "exportacao" in f.name]
                
                csv_result["csv_downloads"] = {
                    "total": len(arquivos_downloads),
                    "importacoes": len(importacoes),
                    "exportacoes": len(exportacoes)
                }
        except Exception as e:
            csv_result["erro"] = str(e)
        
        resultados["arquivos_csv"] = csv_result
        
        # 4. Validar Relacionamentos
        logger.info("ðŸ” Validando relacionamentos...")
        rel_result = {"empresas_recomendadas": {}, "relacionamento_operacoes_empresas": {}}
        
        try:
            total_recomendadas = db.query(func.count(EmpresasRecomendadas.id)).scalar()
            rel_result["empresas_recomendadas"]["total"] = total_recomendadas
            
            if total_recomendadas > 0:
                importadoras = db.query(func.count(EmpresasRecomendadas.id)).filter(
                    EmpresasRecomendadas.tipo_principal == "importadora"
                ).scalar()
                exportadoras = db.query(func.count(EmpresasRecomendadas.id)).filter(
                    EmpresasRecomendadas.tipo_principal == "exportadora"
                ).scalar()
                
                rel_result["empresas_recomendadas"]["importadoras"] = importadoras
                rel_result["empresas_recomendadas"]["exportadoras"] = exportadoras
                
                com_cnpj = db.query(func.count(EmpresasRecomendadas.id)).filter(
                    EmpresasRecomendadas.cnpj.isnot(None)
                ).scalar()
                rel_result["empresas_recomendadas"]["com_cnpj"] = com_cnpj
            
            # Relacionamento operacoes_comex â†” empresas
            cnpjs_operacoes = db.query(func.distinct(OperacaoComex.cnpj_importador)).filter(
                OperacaoComex.cnpj_importador.isnot(None)
            ).all()
            cnpjs_operacoes = [c[0] for c in cnpjs_operacoes if c[0]]
            
            cnpjs_empresas = db.query(func.distinct(Empresa.cnpj)).filter(
                Empresa.cnpj.isnot(None)
            ).all()
            cnpjs_empresas = [c[0] for c in cnpjs_empresas if c[0]]
            
            cnpjs_relacionados = len(set(cnpjs_operacoes) & set(cnpjs_empresas))
            
            rel_result["relacionamento_operacoes_empresas"] = {
                "cnpjs_operacoes": len(cnpjs_operacoes),
                "cnpjs_empresas": len(cnpjs_empresas),
                "cnpjs_relacionados": cnpjs_relacionados,
                "percentual_relacionado": round((cnpjs_relacionados / len(cnpjs_operacoes) * 100) if cnpjs_operacoes else 0, 2)
            }
        except Exception as e:
            rel_result["erro"] = str(e)
        
        resultados["relacionamentos"] = rel_result
        
        # 5. Gerar Resumo
        resumo = {
            "status_geral": "OK",
            "problemas": [],
            "recomendacoes": []
        }
        
        if not bigquery_result.get("conectado"):
            resumo["status_geral"] = "ATENÃ‡ÃƒO"
            resumo["problemas"].append("BigQuery nÃ£o conectado")
            resumo["recomendacoes"].append("Configure GOOGLE_APPLICATION_CREDENTIALS_JSON no Render")
        
        if banco_result["total_registros"].get("operacoes_comex", 0) == 0:
            resumo["status_geral"] = "ATENÃ‡ÃƒO"
            resumo["problemas"].append("Tabela operacoes_comex estÃ¡ vazia")
            resumo["recomendacoes"].append("Execute coleta de dados do Comex Stat")
        
        if banco_result["total_registros"].get("empresas", 0) == 0:
            resumo["problemas"].append("Tabela empresas estÃ¡ vazia")
            resumo["recomendacoes"].append("Execute coleta de dados do BigQuery (Base dos Dados)")
        
        if rel_result["empresas_recomendadas"].get("total", 0) == 0:
            resumo["problemas"].append("Tabela empresas_recomendadas estÃ¡ vazia")
            resumo["recomendacoes"].append("Execute script de anÃ¡lise de sinergias")
        
        if rel_result["relacionamento_operacoes_empresas"].get("cnpjs_relacionados", 0) == 0:
            resumo["problemas"].append("Nenhum relacionamento entre operacoes_comex e empresas")
            resumo["recomendacoes"].append("Execute script de anÃ¡lise de sinergias para criar relacionamentos")
        
        resultados["resumo"] = resumo
        
        return resultados
        
    except Exception as e:
        logger.error(f"Erro na validaÃ§Ã£o: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erro na validaÃ§Ã£o: {str(e)}")


@app.post("/coletar-dados")
async def coletar_dados(db: Session = Depends(get_db)):
    """
    Inicia coleta de dados do Comex Stat.
    """
    try:
        collector = DataCollector()
        stats = await collector.collect_recent_data(db)
        
        return {
            "success": True,
            "message": "Coleta de dados concluÃ­da",
            "stats": stats
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao coletar dados: {str(e)}")


@app.post("/coletar-dados-enriquecidos")
async def coletar_dados_enriquecidos(
    meses: int = Query(24, description="NÃºmero de meses para coletar"),
    db: Session = Depends(get_db)
):
    """
    Coleta dados CSV do portal oficial do MDIC e enriquece com empresas e CNAE.
    Este endpoint:
    1. Baixa tabelas de correlaÃ§Ã£o do MDIC
    2. Baixa dados mensais de importaÃ§Ã£o/exportaÃ§Ã£o dos Ãºltimos N meses
    3. Processa e salva no banco de dados
    4. Enriquece com informaÃ§Ãµes de empresas do MDIC
    5. Integra com CNAE para sugestÃµes inteligentes
    
    Fonte: https://www.gov.br/mdic/pt-br/assuntos/comercio-exterior/estatisticas/base-de-dados-bruta
    """
    try:
        from data_collector.enriched_collector import EnrichedDataCollector
        
        logger.info(f"Iniciando coleta enriquecida de dados do MDIC ({meses} meses)...")
        
        collector = EnrichedDataCollector()
        stats = await collector.collect_and_enrich(db, meses)
        
        return {
            "success": True,
            "message": "Coleta enriquecida concluÃ­da",
            "stats": stats,
            "tabelas_baixadas": list(stats.get("tabelas_correlacao", {}).keys()),
            "empresas_enriquecidas": stats.get("empresas_enriquecidas", 0)
        }
    except Exception as e:
        logger.error(f"Erro na coleta enriquecida: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erro na coleta enriquecida: {str(e)}")


class ColetarDadosNCMsRequest(BaseModel):
    """Schema para coletar dados de mÃºltiplos NCMs."""
    ncms: Optional[List[str]] = None  # Lista de NCMs especÃ­ficos (None = todos)
    meses: Optional[int] = 24  # Quantos meses buscar (padrÃ£o: 24)
    tipo_operacao: Optional[str] = None  # "ImportaÃ§Ã£o" ou "ExportaÃ§Ã£o" (None = ambos)


@app.post("/coletar-dados-ncms")
async def coletar_dados_ncms(
    request: ColetarDadosNCMsRequest,
    db: Session = Depends(get_db)
):
    """
    Coleta dados reais da API Comex Stat ou CSV scraper para mÃºltiplos NCMs.
    Sistema de fallback automÃ¡tico:
    1. Tenta API REST primeiro
    2. Se falhar, usa CSV scraper (bases de dados brutas)
    3. Se falhar, usa scraper tradicional (se disponÃ­vel)
    
    Se ncms nÃ£o for fornecido, coleta dados gerais (todos os NCMs).
    """
    try:
        from datetime import datetime, timedelta
        from data_collector import DataCollector
        
        collector = DataCollector()
        stats = {
            "total_registros": 0,
            "meses_processados": [],
            "erros": [],
            "ncms_processados": [],
            "usou_api": False,
            "metodo_usado": "desconhecido"
        }
        
        # Calcular meses a buscar
        meses = request.meses or 24
        hoje = datetime.now()
        meses_lista = []
        for i in range(meses):
            mes_date = hoje - timedelta(days=30 * i)
            meses_lista.append(mes_date.strftime("%Y-%m"))
        meses_lista = sorted(meses_lista)
        
        # Se nÃ£o especificar NCMs, usar mÃ©todo coletivo (mais eficiente)
        if not request.ncms or len(request.ncms) == 0:
            logger.info(f"Coletando dados gerais (todos os NCMs) para {meses} meses...")
            logger.info("Sistema tentarÃ¡: API â†’ CSV Scraper â†’ Scraper tradicional")
            
            # Usar o mÃ©todo coletivo do DataCollector que tem fallback automÃ¡tico
            try:
                # Ajustar meses no collector temporariamente
                original_months = settings.months_to_fetch
                settings.months_to_fetch = meses
                
                # Coletar dados (com fallback automÃ¡tico)
                collection_stats = await collector.collect_recent_data(db)
                
                # Restaurar configuraÃ§Ã£o
                settings.months_to_fetch = original_months
                
                stats.update(collection_stats)
                stats["metodo_usado"] = "API" if collection_stats.get("usou_api") else "CSV Scraper ou Scraper"
                
            except Exception as e:
                logger.error(f"Erro na coleta coletiva: {e}")
                stats["erros"].append(f"Coleta coletiva: {str(e)}")
        else:
            # Coletar dados especÃ­ficos de cada NCM (via API apenas por enquanto)
            logger.info(f"Coletando dados para {len(request.ncms)} NCMs especÃ­ficos...")
            
            # Verificar se API estÃ¡ disponÃ­vel
            if await collector.api_client.test_connection():
                stats["usou_api"] = True
                stats["metodo_usado"] = "API"
                
                for ncm in request.ncms:
                    ncm_limpo = ncm.replace('.', '').replace(' ', '').strip()
                    if len(ncm_limpo) != 8 or not ncm_limpo.isdigit():
                        logger.warning(f"NCM invÃ¡lido ignorado: {ncm}")
                        continue
                    
                    try:
                        tipos = ["ImportaÃ§Ã£o", "ExportaÃ§Ã£o"]
                        if request.tipo_operacao:
                            tipos = [request.tipo_operacao]
                        
                        for tipo in tipos:
                            logger.info(f"Coletando NCM {ncm_limpo} - {tipo}...")
                            for mes in meses_lista:
                                try:
                                    data = await collector.api_client.fetch_data(
                                        mes_inicio=mes,
                                        mes_fim=mes,
                                        tipo_operacao=tipo,
                                        ncm=ncm_limpo
                                    )
                                    
                                    if data:
                                        transformed = collector.transformer.transform_api_data(data, mes, tipo)
                                        saved = collector._save_to_database(db, transformed, mes, tipo)
                                        stats["total_registros"] += saved
                                
                                except Exception as e:
                                    logger.warning(f"Erro ao coletar {ncm_limpo} - {mes}: {e}")
                                    continue
                        
                        stats["ncms_processados"].append(ncm_limpo)
                        logger.info(f"âœ“ NCM {ncm_limpo} processado")
                    except Exception as e:
                        error_msg = f"Erro ao coletar NCM {ncm}: {e}"
                        logger.error(error_msg)
                        stats["erros"].append(error_msg)
            else:
                # Se API nÃ£o disponÃ­vel e NCMs especÃ­ficos, sugerir coleta geral
                stats["erros"].append(
                    "API nÃ£o disponÃ­vel para NCMs especÃ­ficos. "
                    "Use coleta geral (sem especificar NCMs) para usar CSV scraper."
                )
        
        return {
            "success": True,
            "message": f"Coleta concluÃ­da: {stats['total_registros']} registros usando {stats.get('metodo_usado', 'desconhecido')}",
            "stats": stats
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erro ao coletar dados: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erro ao coletar dados: {str(e)}")


class PopularDadosRequest(BaseModel):
    """Schema para popular dados de exemplo."""
    quantidade: int = 1000
    meses: int = 24


@app.post("/popular-dados-exemplo")
async def popular_dados_exemplo(
    request: PopularDadosRequest,
    db: Session = Depends(get_db)
):
    """
    Popula o banco de dados com dados de exemplo.
    Ãštil para testes quando nÃ£o hÃ¡ acesso ao Shell.
    """
    try:
        from scripts.popular_dados_exemplo import gerar_dados_exemplo
        
        logger.info(f"Iniciando populaÃ§Ã£o de {request.quantidade} registros...")
        
        registros_criados = gerar_dados_exemplo(request.quantidade)
        
        # Verificar quantas empresas foram criadas
        from sqlalchemy import func, distinct
        total_importadoras = db.query(func.count(distinct(OperacaoComex.razao_social_importador))).filter(
            OperacaoComex.razao_social_importador.isnot(None),
            OperacaoComex.razao_social_importador != ''
        ).scalar() or 0
        
        total_exportadoras = db.query(func.count(distinct(OperacaoComex.razao_social_exportador))).filter(
            OperacaoComex.razao_social_exportador.isnot(None),
            OperacaoComex.razao_social_exportador != ''
        ).scalar() or 0
        
        return {
            "success": True,
            "message": f"Banco populado com {registros_criados} registros",
            "registros_criados": registros_criados,
            "quantidade_solicitada": request.quantidade,
            "empresas_importadoras": total_importadoras or 0,
            "empresas_exportadoras": total_exportadoras or 0
        }
    except Exception as e:
        logger.error(f"Erro ao popular dados: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erro ao popular dados: {str(e)}")


@app.get("/test/empresas")
async def test_empresas(db: Session = Depends(get_db)):
    """
    Endpoint de teste para verificar empresas no banco.
    """
    from sqlalchemy import func, distinct
    
    try:
        # Contar total de registros
        total_registros = db.query(OperacaoComex).count()
        
        # Contar empresas importadoras distintas
        importadoras = db.query(
            distinct(OperacaoComex.razao_social_importador)
        ).filter(
            OperacaoComex.razao_social_importador.isnot(None),
            OperacaoComex.razao_social_importador != ''
        ).limit(10).all()
        
        # Contar empresas exportadoras distintas
        exportadoras = db.query(
            distinct(OperacaoComex.razao_social_exportador)
        ).filter(
            OperacaoComex.razao_social_exportador.isnot(None),
            OperacaoComex.razao_social_exportador != ''
        ).limit(10).all()
        
        # Contar totais distintos
        total_imp_distintas = db.query(
            func.count(distinct(OperacaoComex.razao_social_importador))
        ).filter(
            OperacaoComex.razao_social_importador.isnot(None),
            OperacaoComex.razao_social_importador != ''
        ).scalar() or 0
        
        total_exp_distintas = db.query(
            func.count(distinct(OperacaoComex.razao_social_exportador))
        ).filter(
            OperacaoComex.razao_social_exportador.isnot(None),
            OperacaoComex.razao_social_exportador != ''
        ).scalar() or 0
        
        # Valores totais
        valor_total_imp = db.query(func.sum(OperacaoComex.valor_fob)).filter(
            OperacaoComex.tipo_operacao == TipoOperacao.IMPORTACAO
        ).scalar() or 0
        
        valor_total_exp = db.query(func.sum(OperacaoComex.valor_fob)).filter(
            OperacaoComex.tipo_operacao == TipoOperacao.EXPORTACAO
        ).scalar() or 0
        
        # Testar autocomplete
        teste_autocomplete_imp = db.query(
            OperacaoComex.razao_social_importador.label('empresa'),
            func.count(OperacaoComex.id).label('total_operacoes')
        ).filter(
            OperacaoComex.razao_social_importador.isnot(None),
            OperacaoComex.razao_social_importador != '',
            OperacaoComex.razao_social_importador.ilike("%Importadora%")
        ).group_by(
            OperacaoComex.razao_social_importador
        ).limit(5).all()
        
        teste_autocomplete_exp = db.query(
            OperacaoComex.razao_social_exportador.label('empresa'),
            func.count(OperacaoComex.id).label('total_operacoes')
        ).filter(
            OperacaoComex.razao_social_exportador.isnot(None),
            OperacaoComex.razao_social_exportador != '',
            OperacaoComex.razao_social_exportador.ilike("%Exportadora%")
        ).group_by(
            OperacaoComex.razao_social_exportador
        ).limit(5).all()
        
        return {
            "total_registros": total_registros,
            "exemplo_importadoras": [imp[0] for imp in importadoras if imp[0]],
            "exemplo_exportadoras": [exp[0] for exp in exportadoras if exp[0]],
            "total_importadoras_distintas": total_imp_distintas,
            "total_exportadoras_distintas": total_exp_distintas,
            "valor_total_importacoes": float(valor_total_imp),
            "valor_total_exportacoes": float(valor_total_exp),
            "teste_autocomplete_importadoras": [
                {"nome": emp, "total_operacoes": int(total)} 
                for emp, total in teste_autocomplete_imp
            ],
            "teste_autocomplete_exportadoras": [
                {"nome": emp, "total_operacoes": int(total)} 
                for emp, total in teste_autocomplete_exp
            ],
            "status": "ok" if total_registros > 0 else "vazio",
            "problemas": [
                "Banco estÃ¡ vazio" if total_registros == 0 else None,
                "Nenhuma empresa importadora" if total_imp_distintas == 0 else None,
                "Nenhuma empresa exportadora" if total_exp_distintas == 0 else None,
            ]
        }
    except Exception as e:
        logger.error(f"Erro ao testar empresas: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return {"erro": str(e), "traceback": traceback.format_exc()}


@app.get("/dashboard/stats", response_model=DashboardStats)
async def get_dashboard_stats(
    meses: int = Query(default=24, ge=1, le=24),  # PadrÃ£o: 2 anos
    tipo_operacao: Optional[str] = Query(default=None),
    ncm: Optional[str] = Query(default=None),
    ncms: Optional[List[str]] = Query(default=None),  # MÃºltiplos NCMs
    empresa_importadora: Optional[str] = Query(default=None),
    empresa_exportadora: Optional[str] = Query(default=None),
    db: Session = Depends(get_db)
):
    """
    Retorna estatÃ­sticas para o dashboard.
    Por padrÃ£o busca Ãºltimos 2 anos (24 meses).
    """
    from sqlalchemy import func, and_, or_
    from datetime import datetime, timedelta
    
    # Calcular data inicial (padrÃ£o: 2 anos)
    data_inicio = datetime.now() - timedelta(days=30 * meses)
    
    # Construir filtros base
    base_filters = [OperacaoComex.data_operacao >= data_inicio.date()]
    
    # Aplicar filtro de NCMs (mÃºltiplos ou Ãºnico)
    ncms_filtro = []
    if ncms:
        for ncm_item in ncms:
            ncm_limpo = ncm_item.replace('.', '').replace(' ', '').strip()
            if len(ncm_limpo) == 8 and ncm_limpo.isdigit():
                ncms_filtro.append(ncm_limpo)
    elif ncm:
        ncm_limpo = ncm.replace('.', '').replace(' ', '').strip()
        if len(ncm_limpo) == 8 and ncm_limpo.isdigit():
            ncms_filtro.append(ncm_limpo)
    
    if ncms_filtro:
        if len(ncms_filtro) == 1:
            base_filters.append(OperacaoComex.ncm == ncms_filtro[0])
        else:
            base_filters.append(OperacaoComex.ncm.in_(ncms_filtro))
    
    # Aplicar filtros de empresa
    if empresa_importadora:
        base_filters.append(
            OperacaoComex.razao_social_importador.ilike(f"%{empresa_importadora}%")
        )
    
    if empresa_exportadora:
        base_filters.append(
            OperacaoComex.razao_social_exportador.ilike(f"%{empresa_exportadora}%")
        )
    
    # Aplicar filtro de tipo de operaÃ§Ã£o se fornecido
    tipo_filtro = None
    if tipo_operacao:
        if tipo_operacao.lower() == "importaÃ§Ã£o" or tipo_operacao.lower() == "importacao":
            tipo_filtro = TipoOperacao.IMPORTACAO
        elif tipo_operacao.lower() == "exportaÃ§Ã£o" or tipo_operacao.lower() == "exportacao":
            tipo_filtro = TipoOperacao.EXPORTACAO
    
    # Volume de importaÃ§Ãµes e exportaÃ§Ãµes
    filtros_imp = base_filters + [OperacaoComex.tipo_operacao == TipoOperacao.IMPORTACAO]
    if tipo_filtro == TipoOperacao.IMPORTACAO or tipo_filtro is None:
        volume_imp = db.query(func.sum(OperacaoComex.peso_liquido_kg)).filter(
            and_(*filtros_imp)
        ).scalar() or 0.0
    else:
        volume_imp = 0.0
    
    filtros_exp = base_filters + [OperacaoComex.tipo_operacao == TipoOperacao.EXPORTACAO]
    if tipo_filtro == TipoOperacao.EXPORTACAO or tipo_filtro is None:
        volume_exp = db.query(func.sum(OperacaoComex.peso_liquido_kg)).filter(
            and_(*filtros_exp)
        ).scalar() or 0.0
    else:
        volume_exp = 0.0
    
    # Valor total movimentado
    if tipo_filtro:
        filtros_valor = base_filters + [OperacaoComex.tipo_operacao == tipo_filtro]
    else:
        filtros_valor = base_filters
    
    valor_total = db.query(func.sum(OperacaoComex.valor_fob)).filter(
        and_(*filtros_valor)
    ).scalar() or 0.0
    
    # Valores separados por tipo de operaÃ§Ã£o (se nÃ£o houver filtro de tipo)
    valor_total_imp = 0.0
    valor_total_exp = 0.0
    if tipo_filtro is None:
        # Calcular valores separados apenas se nÃ£o houver filtro de tipo
        filtros_valor_imp = base_filters + [OperacaoComex.tipo_operacao == TipoOperacao.IMPORTACAO]
        valor_total_imp = db.query(func.sum(OperacaoComex.valor_fob)).filter(
            and_(*filtros_valor_imp)
        ).scalar() or 0.0
        
        filtros_valor_exp = base_filters + [OperacaoComex.tipo_operacao == TipoOperacao.EXPORTACAO]
        valor_total_exp = db.query(func.sum(OperacaoComex.valor_fob)).filter(
            and_(*filtros_valor_exp)
        ).scalar() or 0.0
    elif tipo_filtro == TipoOperacao.IMPORTACAO:
        valor_total_imp = valor_total
    elif tipo_filtro == TipoOperacao.EXPORTACAO:
        valor_total_exp = valor_total
    
    # Principais NCMs
    principais_ncms = db.query(
        OperacaoComex.ncm,
        OperacaoComex.descricao_produto,
        func.sum(OperacaoComex.valor_fob).label('total_valor'),
        func.count(OperacaoComex.id).label('total_operacoes')
    ).filter(
        and_(*filtros_valor)
    ).group_by(
        OperacaoComex.ncm,
        OperacaoComex.descricao_produto
    ).order_by(
        func.sum(OperacaoComex.valor_fob).desc()
    ).limit(10).all()
    
    principais_ncms_list = [
        {
            "ncm": ncm,
            "descricao": desc[:100] if desc else "",
            "valor_total": float(total_valor),
            "total_operacoes": total_operacoes
        }
        for ncm, desc, total_valor, total_operacoes in principais_ncms
    ]
    
    # Principais paÃ­ses
    principais_paises = db.query(
        OperacaoComex.pais_origem_destino,
        func.sum(OperacaoComex.valor_fob).label('total_valor'),
        func.count(OperacaoComex.id).label('total_operacoes')
    ).filter(
        and_(*filtros_valor)
    ).group_by(
        OperacaoComex.pais_origem_destino
    ).order_by(
        func.sum(OperacaoComex.valor_fob).desc()
    ).limit(10).all()
    
    principais_paises_list = [
        {
            "pais": pais,
            "valor_total": float(total_valor),
            "total_operacoes": total_operacoes
        }
        for pais, total_valor, total_operacoes in principais_paises
    ]
    
    # Se nÃ£o houver paÃ­ses no banco, tentar usar empresas recomendadas
    if not principais_paises_list:
        try:
            # Buscar empresas importadoras e exportadoras recomendadas
            empresas_imp = _buscar_empresas_importadoras_recomendadas(5)
            empresas_exp = _buscar_empresas_exportadoras_recomendadas(5)
            
            principais_paises_list.extend(empresas_imp)
            principais_paises_list.extend(empresas_exp)
            
            # Ordenar por valor total e limitar
            principais_paises_list.sort(key=lambda x: x.get("valor_total", 0), reverse=True)
            principais_paises_list = principais_paises_list[:10]
        except Exception as e:
            logger.debug(f"Erro ao buscar empresas recomendadas para paÃ­ses: {e}")
    
    # Registros por mÃªs com valores FOB e peso
    registros_por_mes_query = db.query(
        OperacaoComex.mes_referencia,
        func.count(OperacaoComex.id).label('count'),
        func.sum(OperacaoComex.valor_fob).label('valor_total'),
        func.sum(OperacaoComex.peso_liquido_kg).label('peso_total')
    ).filter(
        and_(*filtros_valor)
    ).group_by(
        OperacaoComex.mes_referencia
    ).order_by(
        OperacaoComex.mes_referencia
    ).all()
    
    registros_dict = {
        mes: count for mes, count, _, _ in registros_por_mes_query
    }
    
    valores_por_mes_dict = {
        mes: float(valor_total) if valor_total else 0.0
        for mes, _, valor_total, _ in registros_por_mes_query
    }
    
    pesos_por_mes_dict = {
        mes: float(peso_total) if peso_total else 0.0
        for mes, _, _, peso_total in registros_por_mes_query
    }
    
    # Se nÃ£o houver dados no banco, tentar usar dados do Excel
    if valor_total == 0 and not principais_ncms_list:
        try:
            import json
            from pathlib import Path
            
            arquivo_resumo = Path(__file__).parent.parent / "data" / "resumo_dados_comexstat.json"
            if arquivo_resumo.exists():
                with open(arquivo_resumo, 'r', encoding='utf-8') as f:
                    resumo_excel = json.load(f)
                
                # Usar dados do Excel para popular o dashboard
                if resumo_excel.get('importacoes'):
                    valor_total_imp = resumo_excel['importacoes'].get('valor_total_usd', 0)
                    volume_imp = resumo_excel['importacoes'].get('total_registros', 0) * 1000  # Estimativa
                
                if resumo_excel.get('exportacoes'):
                    valor_total_exp = resumo_excel['exportacoes'].get('valor_total_usd', 0)
                    volume_exp = resumo_excel['exportacoes'].get('total_registros', 0) * 1000  # Estimativa
                
                valor_total = valor_total_imp + valor_total_exp
                
                # Criar registros por mÃªs baseado no Excel (distribuir ao longo de 12 meses)
                registros_dict = {}
                valores_por_mes_dict = {}
                pesos_por_mes_dict = {}
                
                meses_2025 = [f"2025-{str(i).zfill(2)}" for i in range(1, 13)]
                total_registros_imp = resumo_excel.get('importacoes', {}).get('total_registros', 0)
                total_registros_exp = resumo_excel.get('exportacoes', {}).get('total_registros', 0)
                
                for mes in meses_2025:
                    registros_dict[mes] = int((total_registros_imp + total_registros_exp) / 12)
                    valores_por_mes_dict[mes] = float((valor_total_imp + valor_total_exp) / 12)
                    pesos_por_mes_dict[mes] = float((volume_imp + volume_exp) / 12)
                
                # Top NCMs do Excel
                arquivo_ncm = Path(__file__).parent.parent / "data" / "dados_ncm_comexstat.json"
                if arquivo_ncm.exists():
                    with open(arquivo_ncm, 'r', encoding='utf-8') as f:
                        dados_ncm = json.load(f)
                    
                    # Agrupar por NCM e ordenar
                    ncms_agrupados = {}
                    for item in dados_ncm:
                        ncm = item.get('ncm', '')
                        if ncm:
                            if ncm not in ncms_agrupados:
                                ncms_agrupados[ncm] = {
                                    'ncm': ncm,
                                    'descricao': item.get('descricao', ''),
                                    'valor_total': 0,
                                    'total_operacoes': 0
                                }
                            ncms_agrupados[ncm]['valor_total'] += item.get('valor_importacao_usd', 0) + item.get('valor_exportacao_usd', 0)
                            ncms_agrupados[ncm]['total_operacoes'] += 1
                    
                    principais_ncms_list = sorted(
                        ncms_agrupados.values(),
                        key=lambda x: x['valor_total'],
                        reverse=True
                    )[:10]
        except Exception as e:
            logger.debug(f"Erro ao carregar dados do Excel: {e}")
    
    # PRIMEIRO: Tentar usar tabela consolidada EmpresasRecomendadas (mais eficiente)
    try:
        total_emp_rec = db.query(func.count(EmpresasRecomendadas.id)).scalar() or 0
        if total_emp_rec > 0:
            logger.info(f"Usando tabela consolidada EmpresasRecomendadas ({total_emp_rec} empresas)")
            
            # Buscar empresas provÃ¡veis importadoras e exportadoras
            empresas_imp_rec = db.query(
                EmpresasRecomendadas.nome,
                EmpresasRecomendadas.valor_total_importacao_usd,
                EmpresasRecomendadas.volume_total_importacao_kg,
                EmpresasRecomendadas.peso_participacao
            ).filter(
                EmpresasRecomendadas.provavel_importador == 1
            ).order_by(
                EmpresasRecomendadas.peso_participacao.desc()
            ).limit(10).all()
            
            empresas_exp_rec = db.query(
                EmpresasRecomendadas.nome,
                EmpresasRecomendadas.valor_total_exportacao_usd,
                EmpresasRecomendadas.volume_total_exportacao_kg,
                EmpresasRecomendadas.peso_participacao
            ).filter(
                EmpresasRecomendadas.provavel_exportador == 1
            ).order_by(
                EmpresasRecomendadas.peso_participacao.desc()
            ).limit(10).all()
            
            # Calcular totais
            valor_total_imp = sum(float(emp.valor_total_importacao_usd or 0) for emp in empresas_imp_rec)
            valor_total_exp = sum(float(emp.valor_total_exportacao_usd or 0) for emp in empresas_exp_rec)
            volume_imp = sum(float(emp.volume_total_importacao_kg or 0) for emp in empresas_imp_rec)
            volume_exp = sum(float(emp.volume_total_exportacao_kg or 0) for emp in empresas_exp_rec)
            
            if valor_total_imp > 0 or valor_total_exp > 0:
                valor_total = valor_total_imp + valor_total_exp
                
                # Usar empresas recomendadas como principais paÃ­ses (temporÃ¡rio)
                principais_paises_list = [
                    {
                        "pais": emp.nome[:50],
                        "valor_total": float(emp.valor_total_importacao_usd or 0),
                        "total_operacoes": 0,
                        "tipo": "IMPORTADORA"
                    }
                    for emp in empresas_imp_rec[:5]
                ] + [
                    {
                        "pais": emp.nome[:50],
                        "valor_total": float(emp.valor_total_exportacao_usd or 0),
                        "total_operacoes": 0,
                        "tipo": "EXPORTADORA"
                    }
                    for emp in empresas_exp_rec[:5]
                ]
                
                principais_paises_list.sort(key=lambda x: x.get("valor_total", 0), reverse=True)
                principais_paises_list = principais_paises_list[:10]
                
                logger.info(f"âœ… Dados carregados da tabela consolidada: {len(empresas_imp_rec)} importadoras, {len(empresas_exp_rec)} exportadoras")
    except Exception as e:
        logger.debug(f"Erro ao buscar EmpresasRecomendadas: {e}")
    
    # Se ainda nÃ£o houver dados, tentar usar as novas tabelas (ComercioExterior e Empresa)
    if valor_total == 0 and not principais_ncms_list:
        try:
            logger.info("Tentando buscar dados das novas tabelas (ComercioExterior e Empresa)")
            data_corte = datetime.now() - timedelta(days=30 * meses)
            
            # Primeiro tentar com filtro de data
            importacoes = db.query(func.sum(ComercioExterior.valor_usd)).filter(
                ComercioExterior.tipo == 'importacao',
                ComercioExterior.data >= data_corte.date()
            ).scalar() or 0.0
            
            exportacoes = db.query(func.sum(ComercioExterior.valor_usd)).filter(
                ComercioExterior.tipo == 'exportacao',
                ComercioExterior.data >= data_corte.date()
            ).scalar() or 0.0
            
            peso_imp = db.query(func.sum(ComercioExterior.peso_kg)).filter(
                ComercioExterior.tipo == 'importacao',
                ComercioExterior.data >= data_corte.date()
            ).scalar() or 0.0
            
            peso_exp = db.query(func.sum(ComercioExterior.peso_kg)).filter(
                ComercioExterior.tipo == 'exportacao',
                ComercioExterior.data >= data_corte.date()
            ).scalar() or 0.0
            
            # Se nÃ£o encontrou com filtro de data, tentar SEM filtro (buscar todos os dados)
            if importacoes == 0 and exportacoes == 0:
                logger.info("Nenhum dado encontrado com filtro de data, buscando todos os dados disponÃ­veis...")
                importacoes = db.query(func.sum(ComercioExterior.valor_usd)).filter(
                    ComercioExterior.tipo == 'importacao'
                ).scalar() or 0.0
                
                exportacoes = db.query(func.sum(ComercioExterior.valor_usd)).filter(
                    ComercioExterior.tipo == 'exportacao'
                ).scalar() or 0.0
                
                peso_imp = db.query(func.sum(ComercioExterior.peso_kg)).filter(
                    ComercioExterior.tipo == 'importacao'
                ).scalar() or 0.0
                
                peso_exp = db.query(func.sum(ComercioExterior.peso_kg)).filter(
                    ComercioExterior.tipo == 'exportacao'
                ).scalar() or 0.0
                
                # Se encontrou dados sem filtro, usar todos os dados (sem filtro de data)
                if importacoes > 0 or exportacoes > 0:
                    data_corte = None  # Remover filtro de data
            
            if importacoes > 0 or exportacoes > 0:
                # Top NCMs
                query_ncms = db.query(
                    ComercioExterior.ncm,
                    ComercioExterior.descricao_ncm,
                    func.sum(ComercioExterior.valor_usd).label('valor_total')
                )
                
                if data_corte:
                    query_ncms = query_ncms.filter(ComercioExterior.data >= data_corte.date())
                
                top_ncms_novo = query_ncms.group_by(
                    ComercioExterior.ncm,
                    ComercioExterior.descricao_ncm
                ).order_by(
                    func.sum(ComercioExterior.valor_usd).desc()
                ).limit(10).all()
                
                principais_ncms_list = [
                    {
                        "ncm": ncm,
                        "descricao": desc or "",
                        "valor_total": float(valor)
                    }
                    for ncm, desc, valor in top_ncms_novo
                ]
                
                # Top Estados
                query_estados = db.query(
                    ComercioExterior.estado,
                    func.sum(ComercioExterior.valor_usd).label('valor_total')
                ).filter(
                    ComercioExterior.estado.isnot(None)
                )
                
                if data_corte:
                    query_estados = query_estados.filter(ComercioExterior.data >= data_corte.date())
                
                top_estados_novo = query_estados.group_by(
                    ComercioExterior.estado
                ).order_by(
                    func.sum(ComercioExterior.valor_usd).desc()
                ).limit(10).all()
                
                principais_paises_list = [
                    {
                        "pais": estado or "N/A",
                        "valor_total": float(valor),
                        "total_operacoes": 0,
                        "tipo": "GERAL"
                    }
                    for estado, valor in top_estados_novo
                ]
                
                # Valores por mÃªs
                query_valores_mes = db.query(
                    ComercioExterior.mes,
                    ComercioExterior.ano,
                    func.sum(ComercioExterior.valor_usd).label('valor_total')
                )
                
                if data_corte:
                    query_valores_mes = query_valores_mes.filter(ComercioExterior.data >= data_corte.date())
                
                valores_por_mes_novo = query_valores_mes.group_by(
                    ComercioExterior.mes,
                    ComercioExterior.ano
                ).order_by(
                    ComercioExterior.ano,
                    ComercioExterior.mes
                ).all()
                
                valores_por_mes_dict = {
                    f"{ano}-{mes:02d}": float(valor)
                    for mes, ano, valor in valores_por_mes_novo
                }
                
                # Pesos por mÃªs
                query_pesos_mes = db.query(
                    ComercioExterior.mes,
                    ComercioExterior.ano,
                    func.sum(ComercioExterior.peso_kg).label('peso_total')
                )
                
                if data_corte:
                    query_pesos_mes = query_pesos_mes.filter(ComercioExterior.data >= data_corte.date())
                
                pesos_por_mes_novo = query_pesos_mes.group_by(
                    ComercioExterior.mes,
                    ComercioExterior.ano
                ).order_by(
                    ComercioExterior.ano,
                    ComercioExterior.mes
                ).all()
                
                pesos_por_mes_dict = {
                    f"{ano}-{mes:02d}": float(peso) if peso else 0.0
                    for mes, ano, peso in pesos_por_mes_novo
                }
                
                # Registros por mÃªs
                query_registros_mes = db.query(
                    ComercioExterior.mes,
                    ComercioExterior.ano,
                    func.count(ComercioExterior.id).label('count')
                )
                
                if data_corte:
                    query_registros_mes = query_registros_mes.filter(ComercioExterior.data >= data_corte.date())
                
                registros_por_mes_novo = query_registros_mes.group_by(
                    ComercioExterior.mes,
                    ComercioExterior.ano
                ).order_by(
                    ComercioExterior.ano,
                    ComercioExterior.mes
                ).all()
                
                registros_dict = {
                    f"{ano}-{mes:02d}": int(count)
                    for mes, ano, count in registros_por_mes_novo
                }
                
                # Atualizar valores
                valor_total_imp = float(importacoes)
                valor_total_exp = float(exportacoes)
                volume_imp = float(peso_imp)
                volume_exp = float(peso_exp)
                valor_total = float(importacoes + exportacoes)
                
                logger.info("="*80)
                logger.info("ðŸ“Š TOTAIS DE COMÃ‰RCIO EXTERIOR")
                logger.info("="*80)
                logger.info(f"ðŸ’° Total ImportaÃ§Ã£o (USD): ${valor_total_imp:,.2f}")
                logger.info(f"ðŸ’° Total ExportaÃ§Ã£o (USD): ${valor_total_exp:,.2f}")
                logger.info(f"ðŸ’° Valor Total (USD): ${valor_total:,.2f}")
                logger.info(f"ðŸ“¦ Volume ImportaÃ§Ã£o (kg): {volume_imp:,.2f}")
                logger.info(f"ðŸ“¦ Volume ExportaÃ§Ã£o (kg): {volume_exp:,.2f}")
                logger.info(f"ðŸ“Š Total de NCMs: {len(principais_ncms_list)}")
                logger.info("="*80)
                
                logger.info(f"âœ… Dados carregados das novas tabelas: {len(principais_ncms_list)} NCMs, {valor_total:.2f} USD total")
        except Exception as e:
            logger.debug(f"Erro ao buscar dados das novas tabelas: {e}")
    
    # Garantir que valores sempre sejam calculados (mesmo que zero)
    if valor_total_imp is None:
        valor_total_imp = 0.0
    if valor_total_exp is None:
        valor_total_exp = 0.0
    
    # Log dos totais finais
    logger.info("="*80)
    logger.info("ðŸ“Š RESUMO FINAL DO DASHBOARD")
    logger.info("="*80)
    logger.info(f"ðŸ’° Total ImportaÃ§Ã£o (USD): ${valor_total_imp:,.2f}")
    logger.info(f"ðŸ’° Total ExportaÃ§Ã£o (USD): ${valor_total_exp:,.2f}")
    logger.info(f"ðŸ’° Valor Total (USD): ${valor_total:,.2f}")
    logger.info(f"ðŸ“¦ Volume ImportaÃ§Ã£o (kg): {volume_imp:,.2f}")
    logger.info(f"ðŸ“¦ Volume ExportaÃ§Ã£o (kg): {volume_exp:,.2f}")
    logger.info(f"ðŸ“Š Total de NCMs: {len(principais_ncms_list)}")
    logger.info(f"ðŸ“Š Total de PaÃ­ses/Estados: {len(principais_paises_list)}")
    logger.info("="*80)
    
    # Se nÃ£o houver dados, retornar resposta vazia rapidamente (nÃ£o travar)
    if valor_total == 0 and not principais_ncms_list and not principais_paises_list:
        logger.warning("âš ï¸ Nenhum dado encontrado, retornando resposta vazia")
        return DashboardStats(
            volume_importacoes=0.0,
            volume_exportacoes=0.0,
            valor_total_usd=0.0,
            valor_total_importacoes=0.0,
            valor_total_exportacoes=0.0,
            principais_ncms=[],
            principais_paises=[],
            registros_por_mes={},
            valores_por_mes={},
            pesos_por_mes={}
        )
    
    stats_response = DashboardStats(
        volume_importacoes=float(volume_imp),
        volume_exportacoes=float(volume_exp),
        valor_total_usd=float(valor_total),
        valor_total_importacoes=float(valor_total_imp) if valor_total_imp > 0 else 0.0,
        valor_total_exportacoes=float(valor_total_exp) if valor_total_exp > 0 else 0.0,
        principais_ncms=principais_ncms_list if principais_ncms_list else [],
        principais_paises=principais_paises_list if principais_paises_list else [],
        registros_por_mes=registros_dict if registros_dict else {},
        valores_por_mes=valores_por_mes_dict if valores_por_mes_dict else {},
        pesos_por_mes=pesos_por_mes_dict if pesos_por_mes_dict else {}
    )
    
    return stats_response


@app.post("/buscar")
async def buscar_operacoes(
    filtros: BuscaFiltros,
    db: Session = Depends(get_db)
):
    """
    Busca operaÃ§Ãµes com filtros avanÃ§ados.
    Por padrÃ£o, busca dados dos Ãºltimos 2 anos se nÃ£o especificar datas.
    """
    from sqlalchemy import and_, or_
    from datetime import datetime, timedelta
    
    query = db.query(OperacaoComex)
    
    # Aplicar filtros
    conditions = []
    
    # Filtro de NCMs (mÃºltiplos)
    ncms_filtro = []
    if filtros.ncms:
        # Limpar e validar NCMs
        for ncm in filtros.ncms:
            ncm_limpo = ncm.replace('.', '').replace(' ', '').strip()
            if len(ncm_limpo) == 8 and ncm_limpo.isdigit():
                ncms_filtro.append(ncm_limpo)
    elif filtros.ncm:
        # Compatibilidade: aceitar NCM Ãºnico tambÃ©m
        ncm_limpo = filtros.ncm.replace('.', '').replace(' ', '').strip()
        if len(ncm_limpo) == 8 and ncm_limpo.isdigit():
            ncms_filtro.append(ncm_limpo)
    
    if ncms_filtro:
        conditions.append(OperacaoComex.ncm.in_(ncms_filtro))
    
    # Por padrÃ£o, buscar Ãºltimos 2 anos se nÃ£o especificar datas
    if not filtros.data_inicio:
        filtros.data_inicio = (datetime.now() - timedelta(days=730)).date()
    if not filtros.data_fim:
        filtros.data_fim = datetime.now().date()
    
    conditions.append(OperacaoComex.data_operacao >= filtros.data_inicio)
    conditions.append(OperacaoComex.data_operacao <= filtros.data_fim)
    
    if filtros.tipo_operacao:
        tipo = TipoOperacao.IMPORTACAO if filtros.tipo_operacao == "ImportaÃ§Ã£o" else TipoOperacao.EXPORTACAO
        conditions.append(OperacaoComex.tipo_operacao == tipo)
    
    if filtros.pais:
        conditions.append(OperacaoComex.pais_origem_destino.ilike(f"%{filtros.pais}%"))
    
    if filtros.uf:
        conditions.append(OperacaoComex.uf == filtros.uf.upper())
    
    if filtros.via_transporte:
        via = ViaTransporte[filtros.via_transporte.upper()]
        conditions.append(OperacaoComex.via_transporte == via)
    
    # Filtros de empresa
    if filtros.empresa_importadora:
        conditions.append(
            OperacaoComex.razao_social_importador.ilike(f"%{filtros.empresa_importadora}%")
        )
    
    if filtros.empresa_exportadora:
        conditions.append(
            OperacaoComex.razao_social_exportador.ilike(f"%{filtros.empresa_exportadora}%")
        )
    
    if filtros.valor_fob_min:
        conditions.append(OperacaoComex.valor_fob >= filtros.valor_fob_min)
    
    if filtros.valor_fob_max:
        conditions.append(OperacaoComex.valor_fob <= filtros.valor_fob_max)
    
    if filtros.peso_min:
        conditions.append(OperacaoComex.peso_liquido_kg >= filtros.peso_min)
    
    if filtros.peso_max:
        conditions.append(OperacaoComex.peso_liquido_kg <= filtros.peso_max)
    
    if conditions:
        query = query.filter(and_(*conditions))
    
    # Contar total
    total = query.count()
    
    # PaginaÃ§Ã£o
    offset = (filtros.page - 1) * filtros.page_size
    operacoes = query.order_by(
        OperacaoComex.data_operacao.desc()
    ).offset(offset).limit(filtros.page_size).all()
    
    return {
        "total": total,
        "page": filtros.page,
        "page_size": filtros.page_size,
        "total_pages": (total + filtros.page_size - 1) // filtros.page_size,
        "results": [
            {
                "id": op.id,
                "ncm": op.ncm,
                "descricao_produto": op.descricao_produto,
                "tipo_operacao": op.tipo_operacao.value,
                "pais_origem_destino": op.pais_origem_destino,
                "uf": op.uf,
                "valor_fob": op.valor_fob,
                "peso_liquido_kg": op.peso_liquido_kg,
                "data_operacao": op.data_operacao.isoformat(),
                "razao_social_importador": op.razao_social_importador,
                "razao_social_exportador": op.razao_social_exportador,
            }
            for op in operacoes
        ]
    }


@app.get("/empresas/autocomplete/importadoras")
async def autocomplete_importadoras(
    q: str = Query("", description="Termo de busca (vazio retorna sugestÃµes)"),
    limit: int = Query(default=20, ge=1, le=100),
    incluir_sugestoes: bool = Query(default=True, description="Incluir empresas sugeridas do MDIC"),
    ncm: Optional[str] = Query(None, description="Filtrar por NCM especÃ­fico"),
    db: Session = Depends(get_db)
):
    """
    Autocomplete para empresas importadoras.
    Retorna empresas que contÃªm o termo de busca no nome.
    Se nÃ£o encontrar resultados, inclui empresas sugeridas do MDIC.
    """
    from sqlalchemy import func, distinct
    
    try:
        resultado = []
        
        # 1. Buscar empresas importadoras que contÃªm o termo nas operaÃ§Ãµes
        empresas = db.query(
            OperacaoComex.razao_social_importador.label('empresa'),
            func.count(OperacaoComex.id).label('total_operacoes'),
            func.sum(OperacaoComex.valor_fob).label('valor_total')
        ).filter(
            OperacaoComex.razao_social_importador.isnot(None),
            OperacaoComex.razao_social_importador != '',
            OperacaoComex.razao_social_importador.ilike(f"%{q}%")
        ).group_by(
            OperacaoComex.razao_social_importador
        ).order_by(
            func.sum(OperacaoComex.valor_fob).desc()
        ).limit(limit).all()
        
        resultado = [
            {
                "nome": empresa,
                "total_operacoes": int(total_operacoes),
                "valor_total": float(valor_total or 0),
                "fonte": "operacoes"
            }
            for empresa, total_operacoes, valor_total in empresas
        ]
        
        # 2. Se nÃ£o encontrou resultados ou quer incluir sugestÃµes, buscar no MDIC
        if (len(resultado) < limit and incluir_sugestoes) or len(resultado) == 0:
            try:
                from data_collector.empresas_mdic_scraper import EmpresasMDICScraper
                # ImportaÃ§Ã£o condicional - apenas quando necessÃ¡rio
                
                scraper = EmpresasMDICScraper()
                empresas_mdic = await scraper.coletar_empresas()
                
                # Filtrar empresas do MDIC que sÃ£o importadoras e contÃªm o termo
                empresas_mdic_filtradas = [
                    emp for emp in empresas_mdic
                    if emp.get("tipo_operacao", "").lower() in ["importaÃ§Ã£o", "importacao", ""] and
                    q.lower() in emp.get("razao_social", "").lower()
                ]
                
                # Adicionar empresas do MDIC que nÃ£o estÃ£o no resultado
                empresas_ja_adicionadas = {r["nome"].lower() for r in resultado}
                
                for emp in empresas_mdic_filtradas[:limit - len(resultado)]:
                    nome = emp.get("razao_social") or emp.get("nome_fantasia", "")
                    if nome.lower() not in empresas_ja_adicionadas:
                        resultado.append({
                            "nome": nome,
                            "total_operacoes": 0,  # NÃ£o temos dados de operaÃ§Ãµes do MDIC
                            "valor_total": 0.0,
                            "fonte": "mdic",
                            "cnpj": emp.get("cnpj"),
                            "uf": emp.get("uf"),
                            "faixa_valor": emp.get("faixa_valor")
                        })
                        empresas_ja_adicionadas.add(nome.lower())
                
            except Exception as e:
                logger.debug(f"Erro ao buscar empresas MDIC para autocomplete: {e}")
        
        # 3. Se ainda nÃ£o tem resultados suficientes, buscar sugestÃµes de sinergias
        if len(resultado) < limit and incluir_sugestoes:
            try:
                # ImportaÃ§Ã£o condicional - apenas quando necessÃ¡rio
                if not SINERGIA_AVAILABLE or SinergiaAnalyzer is None:
                    raise ImportError("SinergiaAnalyzer nÃ£o disponÃ­vel")
                from data_collector.cnae_analyzer import CNAEAnalyzer
                
                # Carregar CNAE se disponÃ­vel
                cnae_analyzer = None
                try:
                    arquivo_cnae = Path("C:/Users/User/Desktop/Cursor/NOVO CNAE.xlsx")
                    if arquivo_cnae.exists():
                        cnae_analyzer = CNAEAnalyzer(arquivo_cnae)
                        cnae_analyzer.carregar_cnae_excel()
                except:
                    pass
                
                analyzer = SinergiaAnalyzer(cnae_analyzer)
                
                # Buscar empresas com sinergia que sÃ£o importadoras
                empresas_com_sinergia = analyzer.analisar_sinergias_por_empresa(db, {}, limit * 2)
                
                # Filtrar empresas que contÃªm o termo e sÃ£o importadoras
                empresas_ja_adicionadas = {r["nome"].lower() for r in resultado}
                
                for emp in empresas_com_sinergia:
                    nome = emp.get("razao_social", "")
                    if (nome.lower() not in empresas_ja_adicionadas and
                        q.lower() in nome.lower() and
                        emp.get("importacoes", {}).get("total_operacoes", 0) > 0):
                        resultado.append({
                            "nome": nome,
                            "total_operacoes": emp.get("importacoes", {}).get("total_operacoes", 0),
                            "valor_total": emp.get("importacoes", {}).get("valor_total", 0.0),
                            "fonte": "sinergia",
                            "potencial_sinergia": emp.get("potencial_sinergia", 0),
                            "cnpj": emp.get("cnpj"),
                            "uf": emp.get("uf")
                        })
                        empresas_ja_adicionadas.add(nome.lower())
                        
                        if len(resultado) >= limit:
                            break
            except Exception as e:
                logger.debug(f"Erro ao buscar sugestÃµes de sinergia: {e}")
        
        return resultado[:limit]
        
    except Exception as e:
        logger.error(f"Erro ao buscar importadoras: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return []


@app.get("/empresas/autocomplete/exportadoras")
async def autocomplete_exportadoras(
    q: str = Query(..., min_length=1, description="Termo de busca"),
    limit: int = Query(default=20, ge=1, le=100),
    incluir_sugestoes: bool = Query(default=True, description="Incluir empresas sugeridas do MDIC"),
    db: Session = Depends(get_db)
):
    """
    Autocomplete para empresas exportadoras.
    Retorna empresas que contÃªm o termo de busca no nome.
    Se nÃ£o encontrar resultados, inclui empresas sugeridas do MDIC e sinergias.
    """
    from sqlalchemy import func
    
    try:
        logger.info(f"ðŸ” Buscando exportadoras com termo: '{q}'")
        
        resultado = []
        query_lower = q.lower() if q else ""
        
        # 1. Se tem query, buscar nas operaÃ§Ãµes primeiro
        if q:
            empresas_query = db.query(
                OperacaoComex.razao_social_exportador,
                func.count(OperacaoComex.id).label('total_operacoes'),
                func.sum(OperacaoComex.valor_fob).label('valor_total')
            ).filter(
                OperacaoComex.razao_social_exportador.isnot(None),
                OperacaoComex.razao_social_exportador != '',
                OperacaoComex.razao_social_exportador.ilike(f"%{q}%")
            ).group_by(
                OperacaoComex.razao_social_exportador
            ).order_by(
                func.sum(OperacaoComex.valor_fob).desc()
            ).limit(limit)
            
            empresas = empresas_query.all()
            
            resultado = []
            for empresa, total_operacoes, valor_total in empresas:
                if empresa:  # Garantir que empresa nÃ£o Ã© None
                    resultado.append({
                        "nome": str(empresa),
                        "total_operacoes": int(total_operacoes) if total_operacoes else 0,
                        "valor_total": float(valor_total or 0),
                        "fonte": "operacoes"
                    })
        
        logger.info(f"âœ… Encontradas {len(resultado)} exportadoras nas operaÃ§Ãµes para '{q}'")
        
        # 2. Se nÃ£o encontrou resultados ou query vazia, buscar no MDIC
        if (len(resultado) < limit and incluir_sugestoes) or not q:
            try:
                from data_collector.empresas_mdic_scraper import EmpresasMDICScraper
                
                scraper = EmpresasMDICScraper()
                empresas_mdic = await scraper.coletar_empresas()
                
                # Filtrar empresas do MDIC que sÃ£o exportadoras e contÃªm o termo
                empresas_mdic_filtradas = [
                    emp for emp in empresas_mdic
                    if emp.get("tipo_operacao", "").lower() in ["exportaÃ§Ã£o", "exportacao", ""] and
                    q.lower() in emp.get("razao_social", "").lower()
                ]
                
                # Adicionar empresas do MDIC que nÃ£o estÃ£o no resultado
                empresas_ja_adicionadas = {r["nome"].lower() for r in resultado}
                
                for emp in empresas_mdic_filtradas[:limit - len(resultado)]:
                    nome = emp.get("razao_social") or emp.get("nome_fantasia", "")
                    if nome.lower() not in empresas_ja_adicionadas:
                        resultado.append({
                            "nome": nome,
                            "total_operacoes": 0,
                            "valor_total": 0.0,
                            "fonte": "mdic",
                            "cnpj": emp.get("cnpj"),
                            "uf": emp.get("uf"),
                            "faixa_valor": emp.get("faixa_valor")
                        })
                        empresas_ja_adicionadas.add(nome.lower())
                
            except Exception as e:
                logger.debug(f"Erro ao buscar empresas MDIC: {e}")
        
        # 3. Se ainda nÃ£o tem resultados suficientes, buscar sugestÃµes de sinergias
        if len(resultado) < limit and incluir_sugestoes:
            try:
                # ImportaÃ§Ã£o condicional - apenas quando necessÃ¡rio
                if not SINERGIA_AVAILABLE or SinergiaAnalyzer is None:
                    raise ImportError("SinergiaAnalyzer nÃ£o disponÃ­vel")
                from data_collector.cnae_analyzer import CNAEAnalyzer
                
                # Carregar CNAE se disponÃ­vel
                cnae_analyzer = None
                try:
                    arquivo_cnae = Path("C:/Users/User/Desktop/Cursor/NOVO CNAE.xlsx")
                    if arquivo_cnae.exists():
                        cnae_analyzer = CNAEAnalyzer(arquivo_cnae)
                        cnae_analyzer.carregar_cnae_excel()
                except:
                    pass
                
                analyzer = SinergiaAnalyzer(cnae_analyzer)
                
                # Buscar empresas com sinergia que sÃ£o exportadoras
                empresas_com_sinergia = analyzer.analisar_sinergias_por_empresa(db, {}, limit * 2)
                
                # Filtrar empresas que contÃªm o termo e sÃ£o exportadoras
                empresas_ja_adicionadas = {r["nome"].lower() for r in resultado}
                
                for emp in empresas_com_sinergia:
                    nome = emp.get("razao_social", "")
                    if (nome.lower() not in empresas_ja_adicionadas and
                        q.lower() in nome.lower() and
                        emp.get("exportacoes", {}).get("total_operacoes", 0) > 0):
                        resultado.append({
                            "nome": nome,
                            "total_operacoes": emp.get("exportacoes", {}).get("total_operacoes", 0),
                            "valor_total": emp.get("exportacoes", {}).get("valor_total", 0.0),
                            "fonte": "sinergia",
                            "potencial_sinergia": emp.get("potencial_sinergia", 0),
                            "cnpj": emp.get("cnpj"),
                            "uf": emp.get("uf")
                        })
                        empresas_ja_adicionadas.add(nome.lower())
                        
                        if len(resultado) >= limit:
                            break
            except Exception as e:
                logger.debug(f"Erro ao buscar sugestÃµes de sinergia: {e}")
        
        return resultado[:limit]
        
    except Exception as e:
        logger.error(f"âŒ Erro ao buscar exportadoras: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return []


@app.get("/ncm/{ncm}/analise")
async def analise_ncm(
    ncm: str,
    db: Session = Depends(get_db)
):
    """
    AnÃ¡lise detalhada de um NCM especÃ­fico.
    """
    from sqlalchemy import func
    
    # Validar NCM
    if len(ncm) != 8 or not ncm.isdigit():
        raise HTTPException(status_code=400, detail="NCM invÃ¡lido")
    
    # EstatÃ­sticas gerais
    stats = db.query(
        func.count(OperacaoComex.id).label('total_operacoes'),
        func.sum(OperacaoComex.valor_fob).label('valor_total'),
        func.sum(OperacaoComex.peso_liquido_kg).label('peso_total'),
        func.avg(OperacaoComex.valor_fob).label('valor_medio')
    ).filter(
        OperacaoComex.ncm == ncm
    ).first()
    
    # Principais paÃ­ses
    principais_paises = db.query(
        OperacaoComex.pais_origem_destino,
        OperacaoComex.tipo_operacao,
        func.sum(OperacaoComex.valor_fob).label('valor_total')
    ).filter(
        OperacaoComex.ncm == ncm
    ).group_by(
        OperacaoComex.pais_origem_destino,
        OperacaoComex.tipo_operacao
    ).order_by(
        func.sum(OperacaoComex.valor_fob).desc()
    ).limit(10).all()
    
    # EvoluÃ§Ã£o temporal
    evolucao = db.query(
        OperacaoComex.mes_referencia,
        OperacaoComex.tipo_operacao,
        func.sum(OperacaoComex.valor_fob).label('valor_total'),
        func.count(OperacaoComex.id).label('quantidade')
    ).filter(
        OperacaoComex.ncm == ncm
    ).group_by(
        OperacaoComex.mes_referencia,
        OperacaoComex.tipo_operacao
    ).order_by(
        OperacaoComex.mes_referencia
    ).all()
    
    return {
        "ncm": ncm,
        "estatisticas": {
            "total_operacoes": stats.total_operacoes or 0,
            "valor_total": float(stats.valor_total or 0),
            "peso_total": float(stats.peso_total or 0),
            "valor_medio": float(stats.valor_medio or 0),
        },
        "principais_paises": [
            {
                "pais": pais,
                "tipo_operacao": tipo.value,
                "valor_total": float(valor_total)
            }
            for pais, tipo, valor_total in principais_paises
        ],
        "evolucao_temporal": [
            {
                "mes": mes,
                "tipo_operacao": tipo.value,
                "valor_total": float(valor_total),
                "quantidade": quantidade
            }
            for mes, tipo, valor_total, quantidade in evolucao
        ]
    }


# Endpoints de AutenticaÃ§Ã£o (opcionais - sÃ³ funcionam se mÃ³dulos estiverem disponÃ­veis)
if AUTH_FUNCTIONS_AVAILABLE and AUTH_AVAILABLE:
    from fastapi import Form
    from fastapi import BackgroundTasks
    import secrets
    from datetime import timedelta
    
    @app.post("/login")
    async def login(
        username: str = Form(...),
        password: str = Form(...),
        db: Session = Depends(get_db)
    ):
        """Endpoint de login usando email."""
        try:
            logger.info(f"Tentativa de login recebida: {username}")
            
            # Truncar senha se necessÃ¡rio (bcrypt limite: 72 bytes)
            senha_original = password
            senha_bytes_original = senha_original.encode('utf-8')
            if len(senha_bytes_original) > 72:
                senha_bytes_truncada = senha_bytes_original[:72]
                senha_final = senha_bytes_truncada.decode('utf-8', errors='ignore')
                logger.warning(f"âš ï¸ Senha truncada de {len(senha_bytes_original)} para 72 bytes")
            else:
                senha_final = senha_original
            
            # username Ã© o email
            user = authenticate_user(db, username, senha_final)
            
            if not user:
                logger.warning(f"Login falhou para: {username}")
                raise HTTPException(
                    status_code=401,
                    detail="Email ou senha incorretos, ou cadastro aguardando aprovaÃ§Ã£o",
                    headers={"WWW-Authenticate": "Bearer"},
                )
            
            # Atualizar Ãºltimo login
            try:
                user.ultimo_login = datetime.utcnow()
                db.commit()
                logger.info(f"âœ… Login bem-sucedido para: {user.email}")
            except Exception as e:
                logger.error(f"Erro ao atualizar Ãºltimo login: {e}")
                db.rollback()
            
            access_token = create_access_token(data={"sub": user.email})
            
            return {
                "access_token": access_token,
                "token_type": "bearer",
                "user": {
                    "id": user.id,
                    "email": user.email,
                    "nome_completo": user.nome_completo,
                    "nome_empresa": user.nome_empresa
                }
            }
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"âŒ Erro inesperado no login: {e}")
            raise HTTPException(status_code=500, detail=f"Erro interno do servidor: {str(e)}")
    
    class CadastroRequest(BaseModel):
        """Schema para cadastro de usuÃ¡rio."""
        email: str
        password: str
        nome_completo: str
        data_nascimento: Optional[date] = None
        nome_empresa: Optional[str] = None
        cpf: Optional[str] = None
        cnpj: Optional[str] = None
    
    @app.post("/register")
    async def register(
        cadastro: CadastroRequest,
        background_tasks: BackgroundTasks,
        db: Session = Depends(get_db)
    ):
        """Endpoint de registro de usuÃ¡rio com aprovaÃ§Ã£o."""
        try:
            logger.info(f"Tentativa de cadastro recebida: {cadastro.email}")
            
            # Validar senha
            senha_valida, mensagem_erro = validate_password(cadastro.password)
            if not senha_valida:
                raise HTTPException(status_code=400, detail=mensagem_erro)
            
            # Verificar se email jÃ¡ existe
            usuario_existente = db.query(Usuario).filter(Usuario.email == cadastro.email).first()
            if usuario_existente:
                raise HTTPException(status_code=400, detail="Email jÃ¡ cadastrado")
            
            # Truncar senha antes do hash
            senha_para_hash = cadastro.password
            senha_bytes = len(senha_para_hash.encode('utf-8'))
            if senha_bytes > 72:
                senha_bytes_truncated = senha_para_hash.encode('utf-8')[:72]
                senha_para_hash = senha_bytes_truncated.decode('utf-8', errors='ignore')
                logger.warning(f"âš ï¸ Senha truncada de {senha_bytes} para 72 bytes")
            
            # Todos os cadastros precisam de aprovaÃ§Ã£o manual
            novo_usuario = Usuario(
                email=cadastro.email,
                senha_hash=get_password_hash(senha_para_hash),
                nome_completo=cadastro.nome_completo,
                data_nascimento=cadastro.data_nascimento,
                nome_empresa=cadastro.nome_empresa,
                cpf=cadastro.cpf,
                cnpj=cadastro.cnpj,
                status_aprovacao="pendente",
                ativo=0  # Inativo atÃ© aprovaÃ§Ã£o
            )
            db.add(novo_usuario)
            db.flush()
            
            # Criar token de aprovaÃ§Ã£o
            token_aprovacao = secrets.token_urlsafe(32)
            data_expiracao = datetime.utcnow() + timedelta(days=7)
            
            aprovacao = AprovacaoCadastro(
                usuario_id=novo_usuario.id,
                token_aprovacao=token_aprovacao,
                email_destino=cadastro.email,
                status="pendente",
                data_expiracao=data_expiracao
            )
            db.add(aprovacao)
            db.commit()
            
            logger.info(f"âœ… UsuÃ¡rio criado: {cadastro.email} (ID: {novo_usuario.id})")
            
            # Enviar email em background
            if EMAIL_SERVICE_AVAILABLE:
                background_tasks.add_task(
                    enviar_email_aprovacao,
                    cadastro.email,
                    cadastro.nome_completo,
                    token_aprovacao
                )
            
            return {
                "message": "Cadastro realizado com sucesso! Aguarde aprovaÃ§Ã£o por email.",
                "email": cadastro.email,
                "aprovado": False
            }
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"âŒ Erro inesperado no cadastro: {e}")
            raise HTTPException(status_code=500, detail=f"Erro interno do servidor: {str(e)}")
    
    class RedefinirSenhaRequest(BaseModel):
        """Schema para solicitar redefiniÃ§Ã£o de senha."""
        email: str
    
    class NovaSenhaRequest(BaseModel):
        """Schema para definir nova senha."""
        token: str
        nova_senha: str
    
    @app.post("/solicitar-redefinicao-senha")
    async def solicitar_redefinicao_senha(
        request: RedefinirSenhaRequest,
        background_tasks: BackgroundTasks,
        db: Session = Depends(get_db)
    ):
        """Endpoint para solicitar redefiniÃ§Ã£o de senha."""
        try:
            usuario = db.query(Usuario).filter(Usuario.email == request.email).first()
            if not usuario:
                # Por seguranÃ§a, nÃ£o revelar se o email existe ou nÃ£o
                logger.info(f"SolicitaÃ§Ã£o de redefiniÃ§Ã£o para email nÃ£o encontrado: {request.email}")
                return {"message": "Se o email existir, vocÃª receberÃ¡ instruÃ§Ãµes para redefinir a senha"}
            
            # Gerar token de redefiniÃ§Ã£o
            token_redefinicao = secrets.token_urlsafe(32)
            
            # Salvar token no banco
            try:
                usuario.token_aprovacao = token_redefinicao
                db.commit()
                logger.info(f"âœ… Token de redefiniÃ§Ã£o salvo para {request.email}")
            except Exception as e:
                logger.error(f"Erro ao salvar token de redefiniÃ§Ã£o: {e}")
                db.rollback()
                raise HTTPException(status_code=500, detail=f"Erro ao processar solicitaÃ§Ã£o: {str(e)}")
            
            # Log do token (em produÃ§Ã£o, enviar por email)
            logger.info(f"ðŸ“§ Token de redefiniÃ§Ã£o gerado para {request.email}: {token_redefinicao}")
            logger.info(f"   Link: http://localhost:3000/redefinir-senha?token={token_redefinicao}")
            
            return {"message": "Se o email existir, vocÃª receberÃ¡ instruÃ§Ãµes para redefinir a senha"}
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Erro ao solicitar redefiniÃ§Ã£o: {e}")
            raise HTTPException(status_code=500, detail="Erro ao processar solicitaÃ§Ã£o")
    
    @app.post("/redefinir-senha")
    async def redefinir_senha(
        request: NovaSenhaRequest,
        db: Session = Depends(get_db)
    ):
        """Endpoint para redefinir senha usando token."""
        try:
            # Validar nova senha
            senha_valida, mensagem_erro = validate_password(request.nova_senha)
            if not senha_valida:
                raise HTTPException(status_code=400, detail=mensagem_erro)
            
            # Buscar usuÃ¡rio pelo token
            usuario = db.query(Usuario).filter(Usuario.token_aprovacao == request.token).first()
            if not usuario:
                raise HTTPException(status_code=400, detail="Token invÃ¡lido ou expirado")
            
            # Truncar senha antes de criar hash
            senha_para_hash = request.nova_senha
            senha_bytes = len(senha_para_hash.encode('utf-8'))
            if senha_bytes > 72:
                senha_bytes_truncated = senha_para_hash.encode('utf-8')[:72]
                senha_para_hash = senha_bytes_truncated.decode('utf-8', errors='ignore')
                logger.warning(f"âš ï¸ Senha truncada de {senha_bytes} para 72 bytes na redefiniÃ§Ã£o")
            
            # Atualizar senha
            usuario.senha_hash = get_password_hash(senha_para_hash)
            usuario.token_aprovacao = None  # Limpar token apÃ³s uso
            db.commit()
            
            logger.info(f"âœ… Senha redefinida para: {usuario.email}")
            return {"message": "Senha redefinida com sucesso"}
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Erro ao redefinir senha: {e}")
            raise HTTPException(status_code=500, detail="Erro ao redefinir senha")
    
    class AprovarCadastroRequest(BaseModel):
        """Schema para aprovar cadastro."""
        token: str
    
    @app.post("/aprovar-cadastro")
    async def aprovar_cadastro(
        request: AprovarCadastroRequest,
        background_tasks: BackgroundTasks,
        db: Session = Depends(get_db)
    ):
        """Endpoint para aprovar cadastro usando token."""
        try:
            # Buscar aprovaÃ§Ã£o pelo token
            aprovacao = db.query(AprovacaoCadastro).filter(
                AprovacaoCadastro.token_aprovacao == request.token,
                AprovacaoCadastro.status == "pendente"
            ).first()
            
            if not aprovacao:
                raise HTTPException(status_code=400, detail="Token invÃ¡lido ou cadastro jÃ¡ processado")
            
            # Verificar se token nÃ£o expirou
            if aprovacao.data_expiracao < datetime.utcnow():
                raise HTTPException(status_code=400, detail="Token expirado")
            
            # Buscar usuÃ¡rio
            usuario = db.query(Usuario).filter(Usuario.id == aprovacao.usuario_id).first()
            if not usuario:
                raise HTTPException(status_code=404, detail="UsuÃ¡rio nÃ£o encontrado")
            
            # Aprovar usuÃ¡rio
            usuario.status_aprovacao = "aprovado"
            usuario.ativo = 1
            aprovacao.status = "aprovado"
            aprovacao.data_aprovacao = datetime.utcnow()
            db.commit()
            
            logger.info(f"âœ… Cadastro aprovado para: {usuario.email}")
            
            # Enviar email de confirmaÃ§Ã£o para o usuÃ¡rio
            if EMAIL_SERVICE_AVAILABLE:
                background_tasks.add_task(
                    enviar_email_cadastro_aprovado,
                    usuario.email,
                    usuario.nome_completo
                )
            
            return {
                "message": "Cadastro aprovado com sucesso!",
                "email": usuario.email,
                "nome": usuario.nome_completo
            }
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Erro ao aprovar cadastro: {e}")
            raise HTTPException(status_code=500, detail="Erro ao aprovar cadastro")
    
    @app.get("/cadastros-pendentes")
    async def listar_cadastros_pendentes(
        db: Session = Depends(get_db)
    ):
        """Lista todos os cadastros pendentes de aprovaÃ§Ã£o."""
        try:
            cadastros = db.query(Usuario).filter(
                Usuario.status_aprovacao == "pendente"
            ).all()
            
            cadastros_list = []
            for c in cadastros:
                # Buscar token de aprovaÃ§Ã£o
                aprovacao = db.query(AprovacaoCadastro).filter(
                    AprovacaoCadastro.usuario_id == c.id,
                    AprovacaoCadastro.status == "pendente"
                ).first()
                
                cadastros_list.append({
                    "id": c.id,
                    "email": c.email,
                    "nome_completo": c.nome_completo,
                    "nome_empresa": c.nome_empresa,
                    "cpf": c.cpf,
                    "cnpj": c.cnpj,
                    "data_criacao": c.data_criacao.isoformat() if c.data_criacao else None,
                    "token_aprovacao": aprovacao.token_aprovacao if aprovacao else None,
                    "link_aprovacao": f"http://localhost:8000/docs#/default/aprovar_cadastro_aprovar_cadastro_post" if aprovacao else None
                })
            
            return {
                "total": len(cadastros_list),
                "cadastros": cadastros_list
            }
        except Exception as e:
            logger.error(f"Erro ao listar cadastros pendentes: {e}")
            import traceback
            logger.error(traceback.format_exc())
            raise HTTPException(status_code=500, detail="Erro ao listar cadastros pendentes")
    
    @app.post("/criar-usuario-teste")
    async def criar_usuario_teste(
        email: str = Form(...),
        senha: str = Form(...),
        nome_completo: str = Form(...),
        db: Session = Depends(get_db)
    ):
        """
        Endpoint para criar usuÃ¡rio jÃ¡ aprovado (apenas para desenvolvimento/teste).
        ATENÃ‡ÃƒO: Em produÃ§Ã£o, considere proteger este endpoint com autenticaÃ§Ã£o admin.
        """
        try:
            # Verificar se usuÃ¡rio jÃ¡ existe
            usuario_existente = db.query(Usuario).filter(Usuario.email == email).first()
            
            if usuario_existente:
                # Atualizar usuÃ¡rio existente
                usuario_existente.senha_hash = get_password_hash(senha)
                usuario_existente.nome_completo = nome_completo
                usuario_existente.status_aprovacao = "aprovado"
                usuario_existente.ativo = 1
                usuario_existente.token_aprovacao = None
                
                db.commit()
                logger.info(f"âœ… UsuÃ¡rio {email} atualizado e aprovado")
                return {
                    "message": "UsuÃ¡rio atualizado e aprovado com sucesso",
                    "email": email,
                    "status": "aprovado"
                }
            
            # Criar novo usuÃ¡rio
            senha_hash = get_password_hash(senha)
            
            novo_usuario = Usuario(
                email=email,
                senha_hash=senha_hash,
                nome_completo=nome_completo,
                status_aprovacao="aprovado",
                ativo=1,
                token_aprovacao=None,
                data_criacao=datetime.utcnow()
            )
            
            db.add(novo_usuario)
            db.commit()
            
            logger.info(f"âœ… UsuÃ¡rio {email} criado e aprovado")
            return {
                "message": "UsuÃ¡rio criado e aprovado com sucesso",
                "email": email,
                "status": "aprovado"
            }
            
        except Exception as e:
            db.rollback()
            logger.error(f"Erro ao criar usuÃ¡rio teste: {e}")
            raise HTTPException(status_code=500, detail=f"Erro ao criar usuÃ¡rio: {str(e)}")
else:
    # Endpoints stub quando autenticaÃ§Ã£o nÃ£o estÃ¡ disponÃ­vel
    @app.post("/login")
    async def login_stub():
        """Endpoint de login nÃ£o disponÃ­vel - mÃ³dulos de autenticaÃ§Ã£o nÃ£o instalados."""
        raise HTTPException(
            status_code=501,
            detail="AutenticaÃ§Ã£o nÃ£o disponÃ­vel. MÃ³dulos de autenticaÃ§Ã£o nÃ£o estÃ£o instalados."
        )
    
    @app.post("/register")
    async def register_stub():
        """Endpoint de registro nÃ£o disponÃ­vel - mÃ³dulos de autenticaÃ§Ã£o nÃ£o instalados."""
        raise HTTPException(
            status_code=501,
            detail="Cadastro nÃ£o disponÃ­vel. MÃ³dulos de autenticaÃ§Ã£o nÃ£o estÃ£o instalados."
        )


# Endpoints para cruzamento de dados com empresas do MDIC
try:
    from data_collector.cruzamento_dados import CruzamentoDados
    from data_collector.empresas_mdic_scraper import EmpresasMDICScraper
    CRUZAMENTO_AVAILABLE = True
except ImportError:
    CRUZAMENTO_AVAILABLE = False
    logger.warning("MÃ³dulos de cruzamento nÃ£o disponÃ­veis")

# Endpoints para anÃ¡lise de sinergias e CNAE
try:
    from data_collector.sinergia_analyzer import SinergiaAnalyzer
    from data_collector.cnae_analyzer import CNAEAnalyzer
    SINERGIA_AVAILABLE = True
except (ImportError, NameError) as e:
    SINERGIA_AVAILABLE = False
    SinergiaAnalyzer = None
    CNAEAnalyzer = None
    logger.warning(f"MÃ³dulos de sinergia nÃ£o disponÃ­veis: {e}")


@app.post("/coletar-empresas-mdic")
async def coletar_empresas_mdic(
    ano: Optional[int] = Query(None, description="Ano especÃ­fico (None = ano atual)"),
    db: Session = Depends(get_db)
):
    """
    Coleta lista de empresas exportadoras e importadoras do MDIC.
    Esta lista contÃ©m CNPJ e nome das empresas, mas sem detalhamento por NCM.
    """
    if not CRUZAMENTO_AVAILABLE:
        raise HTTPException(status_code=501, detail="MÃ³dulo de cruzamento nÃ£o disponÃ­vel")
    
    try:
        scraper = EmpresasMDICScraper()
        empresas = await scraper.coletar_empresas(ano)
        
        return {
            "success": True,
            "message": f"Coletadas {len(empresas)} empresas do MDIC",
            "total_empresas": len(empresas),
            "ano": ano or datetime.now().year,
            "empresas": empresas[:100]  # Retornar primeiras 100 como exemplo
        }
    except Exception as e:
        logger.error(f"Erro ao coletar empresas do MDIC: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erro ao coletar empresas: {str(e)}")


class CruzamentoFiltros(BaseModel):
    """Filtros para cruzamento de dados."""
    ncm: Optional[str] = None
    tipo_operacao: Optional[str] = None
    uf: Optional[str] = None
    limite: int = 1000


@app.post("/cruzar-dados-empresas")
async def cruzar_dados_empresas(
    filtros: CruzamentoFiltros,
    db: Session = Depends(get_db)
):
    """
    Cruza dados de operaÃ§Ãµes com lista de empresas do MDIC.
    Tenta identificar empresas por CNPJ ou razÃ£o social.
    """
    if not CRUZAMENTO_AVAILABLE:
        raise HTTPException(status_code=501, detail="MÃ³dulo de cruzamento nÃ£o disponÃ­vel")
    
    try:
        cruzamento = CruzamentoDados()
        
        filtros_dict = {}
        if filtros.ncm:
            filtros_dict["ncm"] = filtros.ncm
        if filtros.tipo_operacao:
            filtros_dict["tipo_operacao"] = filtros.tipo_operacao
        if filtros.uf:
            filtros_dict["uf"] = filtros.uf
        
        resultados = await cruzamento.cruzar_operacoes_bulk(
            db,
            filtros=filtros_dict if filtros_dict else None,
            limite=filtros.limite
        )
        
        estatisticas = cruzamento.estatisticas_cruzamento(resultados)
        
        return {
            "success": True,
            "message": f"Cruzamento concluÃ­do: {estatisticas['operacoes_identificadas']}/{estatisticas['total_operacoes']} operaÃ§Ãµes identificadas",
            "estatisticas": estatisticas,
            "resultados": resultados[:100]  # Retornar primeiras 100 como exemplo
        }
    except Exception as e:
        logger.error(f"Erro ao cruzar dados: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erro ao cruzar dados: {str(e)}")


@app.get("/estatisticas-cruzamento")
async def estatisticas_cruzamento(
    db: Session = Depends(get_db)
):
    """
    Retorna estatÃ­sticas sobre cruzamento de dados.
    """
    if not CRUZAMENTO_AVAILABLE:
        raise HTTPException(status_code=501, detail="MÃ³dulo de cruzamento nÃ£o disponÃ­vel")
    
    try:
        # Contar operaÃ§Ãµes com CNPJ
        from sqlalchemy import func, or_
        
        total_operacoes = db.query(func.count(OperacaoComex.id)).scalar() or 0
        
        operacoes_com_cnpj = db.query(func.count(OperacaoComex.id)).filter(
            or_(
                OperacaoComex.cnpj_importador.isnot(None),
                OperacaoComex.cnpj_exportador.isnot(None)
            )
        ).scalar() or 0
        
        operacoes_com_razao_social = db.query(func.count(OperacaoComex.id)).filter(
            or_(
                OperacaoComex.razao_social_importador.isnot(None),
                OperacaoComex.razao_social_exportador.isnot(None)
            )
        ).scalar() or 0
        
        return {
            "total_operacoes": total_operacoes,
            "operacoes_com_cnpj": operacoes_com_cnpj,
            "operacoes_com_razao_social": operacoes_com_razao_social,
            "taxa_cnpj": (operacoes_com_cnpj / total_operacoes * 100) if total_operacoes > 0 else 0,
            "taxa_razao_social": (operacoes_com_razao_social / total_operacoes * 100) if total_operacoes > 0 else 0,
            "nota": "Dados pÃºblicos sÃ£o anonimizados. CNPJ/razÃ£o social podem nÃ£o estar disponÃ­veis em todas as operaÃ§Ãµes."
        }
    except Exception as e:
        logger.error(f"Erro ao calcular estatÃ­sticas: {e}")
        raise HTTPException(status_code=500, detail=f"Erro ao calcular estatÃ­sticas: {str(e)}")


@app.post("/carregar-cnae")
async def carregar_cnae(
    arquivo_path: Optional[str] = Query(None, description="Caminho do arquivo Excel CNAE")
):
    """
    Carrega arquivo Excel com classificaÃ§Ã£o CNAE.
    """
    if not SINERGIA_AVAILABLE:
        raise HTTPException(status_code=501, detail="MÃ³dulo de sinergia nÃ£o disponÃ­vel")
    
    try:
        from pathlib import Path
        
        if arquivo_path:
            arquivo = Path(arquivo_path)
        else:
            # Tentar caminho padrÃ£o
            arquivo = Path("C:/Users/User/Desktop/Cursor/NOVO CNAE.xlsx")
        
        analyzer = CNAEAnalyzer(arquivo)
        sucesso = analyzer.carregar_cnae_excel()
        
        if sucesso:
            stats = analyzer.estatisticas()
            return {
                "success": True,
                "message": f"CNAE carregado com sucesso",
                "estatisticas": stats
            }
        else:
            raise HTTPException(status_code=400, detail="NÃ£o foi possÃ­vel carregar arquivo CNAE")
    except Exception as e:
        logger.error(f"Erro ao carregar CNAE: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erro ao carregar CNAE: {str(e)}")


@app.get("/analisar-sinergias-estado")
async def analisar_sinergias_estado(
    uf: Optional[str] = Query(None, description="UF especÃ­fica (None = todos)"),
    db: Session = Depends(get_db)
):
    """
    Analisa sinergias de importaÃ§Ã£o/exportaÃ§Ã£o por estado.
    """
    if not SINERGIA_AVAILABLE or SinergiaAnalyzer is None:
        raise HTTPException(status_code=501, detail="MÃ³dulo de sinergia nÃ£o disponÃ­vel")
    
    try:
        analyzer = SinergiaAnalyzer()
        resultado = analyzer.analisar_sinergias_por_estado(db, uf)
        return resultado
    except Exception as e:
        logger.error(f"Erro ao analisar sinergias: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erro ao analisar sinergias: {str(e)}")


@app.post("/analisar-sinergias-empresas")
async def analisar_sinergias_empresas(
    limite: int = Query(100, description="Limite de empresas a analisar"),
    ano: Optional[int] = Query(None, description="Ano para coletar empresas do MDIC"),
    db: Session = Depends(get_db)
):
    """
    Analisa sinergias por empresa, integrando com CNAE.
    """
    if not SINERGIA_AVAILABLE or not CRUZAMENTO_AVAILABLE:
        raise HTTPException(status_code=501, detail="MÃ³dulos necessÃ¡rios nÃ£o disponÃ­veis")
    
    try:
        # Carregar empresas do MDIC
        scraper = EmpresasMDICScraper()
        empresas_lista = await scraper.coletar_empresas(ano)
        
        # Criar Ã­ndice por CNPJ
        empresas_mdic = {}
        for empresa in empresas_lista:
            cnpj = empresa.get("cnpj")
            if cnpj:
                empresas_mdic[cnpj] = empresa
        
        # Carregar CNAE se disponÃ­vel
        cnae_analyzer = None
        try:
            arquivo_cnae = Path("C:/Users/User/Desktop/Cursor/NOVO CNAE.xlsx")
            if arquivo_cnae.exists():
                cnae_analyzer = CNAEAnalyzer(arquivo_cnae)
                cnae_analyzer.carregar_cnae_excel()
        except Exception as e:
            logger.warning(f"NÃ£o foi possÃ­vel carregar CNAE: {e}")
        
        # Analisar sinergias
        analyzer = SinergiaAnalyzer(cnae_analyzer)
        resultados = analyzer.analisar_sinergias_por_empresa(db, empresas_mdic, limite)
        
        return {
            "success": True,
            "message": f"AnÃ¡lise de sinergias concluÃ­da para {len(resultados)} empresas",
            "total_empresas_mdic": len(empresas_mdic),
            "empresas_analisadas": len(resultados),
            "cnae_carregado": cnae_analyzer is not None,
            "resultados": resultados
        }
    except Exception as e:
        logger.error(f"Erro ao analisar sinergias de empresas: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erro ao analisar sinergias: {str(e)}")


@app.get("/sugestoes-empresa/{cnpj}")
async def sugestoes_empresa(
    cnpj: str,
    db: Session = Depends(get_db)
):
    """
    Gera sugestÃµes de importaÃ§Ã£o/exportaÃ§Ã£o para uma empresa especÃ­fica.
    """
    if not SINERGIA_AVAILABLE:
        raise HTTPException(status_code=501, detail="MÃ³dulo de sinergia nÃ£o disponÃ­vel")
    
    try:
        # Buscar empresa no MDIC
        scraper = EmpresasMDICScraper()
        empresas_lista = await scraper.coletar_empresas()
        
        empresa_mdic = None
        cnpj_limpo = cnpj.replace('.', '').replace('/', '').replace('-', '')
        for empresa in empresas_lista:
            if empresa.get("cnpj") == cnpj_limpo:
                empresa_mdic = empresa
                break
        
        if not empresa_mdic:
            raise HTTPException(status_code=404, detail="Empresa nÃ£o encontrada no MDIC")
        
        # Carregar CNAE
        cnae_analyzer = None
        try:
            arquivo_cnae = Path("C:/Users/User/Desktop/Cursor/NOVO CNAE.xlsx")
            if arquivo_cnae.exists():
                cnae_analyzer = CNAEAnalyzer(arquivo_cnae)
                cnae_analyzer.carregar_cnae_excel()
        except Exception as e:
            logger.warning(f"NÃ£o foi possÃ­vel carregar CNAE: {e}")
        
        # Analisar empresa
        analyzer = SinergiaAnalyzer(cnae_analyzer)
        sinergia = analyzer._analisar_empresa_individual(
            db,
            cnpj_limpo,
            empresa_mdic,
            empresa_mdic.get("uf")
        )
        
        if not sinergia:
            raise HTTPException(status_code=404, detail="NÃ£o foi possÃ­vel analisar empresa")
        
        return {
            "success": True,
            "empresa": sinergia,
            "sugestoes": {
                "importacao": sinergia.get("sugestao", ""),
                "exportacao": sinergia.get("sugestao", ""),
                "cnae": sinergia.get("cnae"),
                "classificacao_cnae": sinergia.get("classificacao_cnae")
            }
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erro ao gerar sugestÃµes: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erro ao gerar sugestÃµes: {str(e)}")


@app.post("/atualizar-dados-completos")
async def atualizar_dados_completos():
    """
    Executa atualizaÃ§Ã£o completa de todos os dados (empresas MDIC, relacionamentos, sinergias).
    Ãštil para atualizaÃ§Ã£o manual ou via scheduler.
    """
    try:
        from utils.data_updater import DataUpdater
        
        updater = DataUpdater()
        resultado = await updater.atualizar_completo()
        
        return resultado
    except Exception as e:
        logger.error(f"Erro na atualizaÃ§Ã£o completa: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erro na atualizaÃ§Ã£o: {str(e)}")


@app.get("/dashboard/sinergias-estado")
async def dashboard_sinergias_estado(
    uf: Optional[str] = Query(None),
    db: Session = Depends(get_db)
):
    """
    Endpoint otimizado para dashboard - sinergias por estado.
    """
    if not SINERGIA_AVAILABLE or SinergiaAnalyzer is None:
        raise HTTPException(status_code=501, detail="MÃ³dulo de sinergia nÃ£o disponÃ­vel")
    
    try:
        analyzer = SinergiaAnalyzer()
        resultado = analyzer.analisar_sinergias_por_estado(db, uf)
        return resultado
    except Exception as e:
        logger.error(f"Erro ao buscar sinergias: {e}")
        raise HTTPException(status_code=500, detail=f"Erro ao buscar sinergias: {str(e)}")


@app.get("/dashboard/sugestoes-empresas")
async def dashboard_sugestoes_empresas(
    limite: int = Query(20, description="NÃºmero de sugestÃµes"),
    tipo: Optional[str] = Query(None, description="Tipo: 'importacao', 'exportacao', ou None para ambos"),
    uf: Optional[str] = Query(None, description="Filtrar por UF"),
    db: Session = Depends(get_db)
):
    """
    Endpoint otimizado para dashboard - sugestÃµes de empresas.
    Retorna empresas com maior potencial de sinergia.
    """
    if not SINERGIA_AVAILABLE or not CRUZAMENTO_AVAILABLE:
        raise HTTPException(status_code=501, detail="MÃ³dulos necessÃ¡rios nÃ£o disponÃ­veis")
    
    try:
        # Carregar empresas
        scraper = EmpresasMDICScraper()
        empresas_lista = await scraper.coletar_empresas()
        empresas_mdic = {}
        for empresa in empresas_lista:
            cnpj = empresa.get("cnpj")
            if cnpj:
                empresas_mdic[cnpj] = empresa
        
        # Carregar CNAE
        cnae_analyzer = None
        try:
            arquivo_cnae = Path("C:/Users/User/Desktop/Cursor/NOVO CNAE.xlsx")
            if arquivo_cnae.exists():
                cnae_analyzer = CNAEAnalyzer(arquivo_cnae)
                cnae_analyzer.carregar_cnae_excel()
        except Exception as e:
            logger.warning(f"NÃ£o foi possÃ­vel carregar CNAE: {e}")
        
        # Analisar sinergias
        analyzer = SinergiaAnalyzer(cnae_analyzer)
        resultados = analyzer.analisar_sinergias_por_empresa(db, empresas_mdic, limite * 2)
        
        # Filtrar por tipo se especificado
        if tipo == "importacao":
            resultados = [r for r in resultados if r["importacoes"]["total_operacoes"] > 0 and r["exportacoes"]["total_operacoes"] == 0]
        elif tipo == "exportacao":
            resultados = [r for r in resultados if r["exportacoes"]["total_operacoes"] > 0 and r["importacoes"]["total_operacoes"] == 0]
        
        # Filtrar por UF se especificado
        if uf:
            resultados = [r for r in resultados if r.get("uf") == uf]
        
        # Ordenar por potencial e limitar
        resultados.sort(key=lambda x: x.get("potencial_sinergia", 0), reverse=True)
        resultados = resultados[:limite]
        
        return {
            "success": True,
            "total": len(resultados),
            "sugestoes": resultados
        }
    except Exception as e:
        logger.error(f"Erro ao buscar sugestÃµes: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erro ao buscar sugestÃµes: {str(e)}")


@app.get("/dashboard/empresas-recomendadas")
async def get_empresas_recomendadas(
    limite: int = Query(default=100, ge=1, le=5000),
    tipo: Optional[str] = Query(default=None, description="Filtrar por tipo: CLIENTE_POTENCIAL ou FORNECEDOR_POTENCIAL"),
    uf: Optional[str] = Query(default=None),
    ncm: Optional[str] = Query(default=None)
):
    """
    Retorna lista de empresas recomendadas para o dashboard.
    """
    try:
        import json
        from pathlib import Path
        
        arquivo_empresas = Path(__file__).parent.parent / "data" / "empresas_recomendadas.xlsx"
        
        if not arquivo_empresas.exists():
            # Tentar CSV como fallback
            arquivo_empresas = Path(__file__).parent.parent / "data" / "empresas_recomendadas.csv"
            if not arquivo_empresas.exists():
                return {
                    "success": False,
                    "message": "Arquivo de empresas recomendadas nÃ£o encontrado",
                    "data": []
                }
        
        import pandas as pd
        
        if arquivo_empresas.suffix == '.xlsx':
            df = pd.read_excel(arquivo_empresas)
        else:
            df = pd.read_csv(arquivo_empresas, encoding='utf-8-sig')
        
        # Aplicar filtros
        if tipo:
            df = df[df['SugestÃ£o'] == tipo]
        if uf:
            df = df[df['Estado'] == uf]
        if ncm:
            df = df[df['NCM Relacionado'] == ncm]
        
        # Limitar resultados
        df = df.head(limite)
        
        # Converter para dict
        empresas = df.to_dict('records')
        
        return {
            "success": True,
            "total": len(empresas),
            "data": empresas
        }
    except Exception as e:
        logger.error(f"Erro ao buscar empresas recomendadas: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erro ao buscar empresas recomendadas: {str(e)}")


def _buscar_empresas_importadoras_recomendadas(limite: int = 10):
    """
    FunÃ§Ã£o auxiliar sÃ­ncrona para buscar empresas importadoras recomendadas.
    """
    try:
        import pandas as pd
        from pathlib import Path
        
        arquivo_empresas = Path(__file__).parent.parent / "data" / "empresas_recomendadas.xlsx"
        
        if not arquivo_empresas.exists():
            arquivo_empresas = Path(__file__).parent.parent / "data" / "empresas_recomendadas.csv"
            if not arquivo_empresas.exists():
                return []
        
        if arquivo_empresas.suffix == '.xlsx':
            df = pd.read_excel(arquivo_empresas)
        else:
            df = pd.read_csv(arquivo_empresas, encoding='utf-8-sig')
        
        # Filtrar empresas que importam (tÃªm valor de importaÃ§Ã£o > 0)
        df_importadoras = df[
            (df['Importado (R$)'].notna()) & 
            (df['Importado (R$)'] > 0)
        ].copy()
        
        # Agrupar por empresa (CNPJ) e somar valores
        df_agrupado = df_importadoras.groupby('CNPJ').agg({
            'RazÃ£o Social': 'first',
            'Nome Fantasia': 'first',
            'Estado': 'first',
            'Importado (R$)': 'sum',
            'Peso ParticipaÃ§Ã£o (0-100)': 'max'
        }).reset_index()
        
        # Ordenar por valor de importaÃ§Ã£o
        df_agrupado = df_agrupado.sort_values('Importado (R$)', ascending=False).head(limite)
        
        # Converter para formato esperado pelo dashboard
        empresas = []
        for _, row in df_agrupado.iterrows():
            empresas.append({
                "pais": row['RazÃ£o Social'] or row['Nome Fantasia'],
                "valor_total": float(row['Importado (R$)']) / 5.0,  # Converter BRL para USD
                "total_operacoes": 1,
                "uf": row.get('Estado', ''),
                "peso_participacao": float(row.get('Peso ParticipaÃ§Ã£o (0-100)', 0))
            })
        
        return empresas
    except Exception as e:
        logger.debug(f"Erro ao buscar empresas importadoras: {e}")
        import traceback
        logger.debug(traceback.format_exc())
        return []


def _buscar_empresas_exportadoras_recomendadas(limite: int = 10):
    """
    FunÃ§Ã£o auxiliar sÃ­ncrona para buscar empresas exportadoras recomendadas.
    """
    try:
        import pandas as pd
        from pathlib import Path
        
        arquivo_empresas = Path(__file__).parent.parent / "data" / "empresas_recomendadas.xlsx"
        
        if not arquivo_empresas.exists():
            arquivo_empresas = Path(__file__).parent.parent / "data" / "empresas_recomendadas.csv"
            if not arquivo_empresas.exists():
                return []
        
        if arquivo_empresas.suffix == '.xlsx':
            df = pd.read_excel(arquivo_empresas)
        else:
            df = pd.read_csv(arquivo_empresas, encoding='utf-8-sig')
        
        # Filtrar empresas que exportam (tÃªm valor de exportaÃ§Ã£o > 0)
        df_exportadoras = df[
            (df['Exportado (R$)'].notna()) & 
            (df['Exportado (R$)'] > 0)
        ].copy()
        
        # Agrupar por empresa (CNPJ) e somar valores
        df_agrupado = df_exportadoras.groupby('CNPJ').agg({
            'RazÃ£o Social': 'first',
            'Nome Fantasia': 'first',
            'Estado': 'first',
            'Exportado (R$)': 'sum',
            'Peso ParticipaÃ§Ã£o (0-100)': 'max'
        }).reset_index()
        
        # Ordenar por valor de exportaÃ§Ã£o
        df_agrupado = df_agrupado.sort_values('Exportado (R$)', ascending=False).head(limite)
        
        # Converter para formato esperado pelo dashboard
        empresas = []
        for _, row in df_agrupado.iterrows():
            empresas.append({
                "pais": row['RazÃ£o Social'] or row['Nome Fantasia'],
                "valor_total": float(row['Exportado (R$)']) / 5.0,  # Converter BRL para USD
                "total_operacoes": 1,
                "uf": row.get('Estado', ''),
                "peso_participacao": float(row.get('Peso ParticipaÃ§Ã£o (0-100)', 0))
            })
        
        return empresas
    except Exception as e:
        logger.debug(f"Erro ao buscar empresas exportadoras: {e}")
        import traceback
        logger.debug(traceback.format_exc())
        return []


@app.get("/dashboard/empresas-importadoras")
async def get_empresas_importadoras_recomendadas(
    limite: int = Query(default=10, ge=1, le=100)
):
    """
    Retorna empresas recomendadas que sÃ£o importadoras (para seÃ§Ã£o "ProvÃ¡veis Importadores").
    """
    empresas = _buscar_empresas_importadoras_recomendadas(limite)
    return {
        "success": True,
        "data": empresas
    }


@app.get("/dashboard/empresas-exportadoras")
async def get_empresas_exportadoras_recomendadas(
    limite: int = Query(default=10, ge=1, le=100)
):
    """
    Retorna empresas recomendadas que sÃ£o exportadoras (para seÃ§Ã£o "ProvÃ¡veis Exportadores").
    """
    empresas = _buscar_empresas_exportadoras_recomendadas(limite)
    return {
        "success": True,
        "data": empresas
    }


@app.get("/dashboard/dados-comexstat")
async def get_dados_comexstat():
    """
    Retorna resumo dos dados do arquivo Excel ComexStat.
    """
    try:
        import json
        from pathlib import Path
        
        arquivo_resumo = Path(__file__).parent.parent / "data" / "resumo_dados_comexstat.json"
        
        if not arquivo_resumo.exists():
            return {
                "success": False,
                "message": "Arquivo de resumo nÃ£o encontrado. Execute o script de processamento primeiro.",
                "data": None
            }
        
        with open(arquivo_resumo, 'r', encoding='utf-8') as f:
            resumo = json.load(f)
        
        return {
            "success": True,
            "data": resumo
        }
    except Exception as e:
        logger.error(f"Erro ao buscar dados ComexStat: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erro ao buscar dados: {str(e)}")


@app.get("/api/validar-dados-banco")
async def validar_dados_banco(db: Session = Depends(get_db)):
    """
    Valida dados no banco e retorna estatÃ­sticas detalhadas.
    """
    from sqlalchemy import func
    from database.models import ComercioExterior, Empresa, OperacaoComex
    
    try:
        # ComercioExterior
        total_comex = db.query(func.count(ComercioExterior.id)).scalar() or 0
        
        total_valor_imp = 0.0
        total_valor_exp = 0.0
        total_peso_imp = 0.0
        total_peso_exp = 0.0
        
        if total_comex > 0:
            total_valor_imp = db.query(func.sum(ComercioExterior.valor_usd)).filter(
                ComercioExterior.tipo == 'importacao'
            ).scalar() or 0.0
            
            total_valor_exp = db.query(func.sum(ComercioExterior.valor_usd)).filter(
                ComercioExterior.tipo == 'exportacao'
            ).scalar() or 0.0
            
            total_peso_imp = db.query(func.sum(ComercioExterior.peso_kg)).filter(
                ComercioExterior.tipo == 'importacao'
            ).scalar() or 0.0
            
            total_peso_exp = db.query(func.sum(ComercioExterior.peso_kg)).filter(
                ComercioExterior.tipo == 'exportacao'
            ).scalar() or 0.0
        
        # Empresas
        total_empresas = db.query(func.count(Empresa.id)).scalar() or 0
        
        # OperacaoComex (tabela antiga)
        total_ops = db.query(func.count(OperacaoComex.id)).scalar() or 0
        
        logger.info("="*80)
        logger.info("ðŸ“Š VALIDAÃ‡ÃƒO DE DADOS NO BANCO")
        logger.info("="*80)
        logger.info(f"ðŸ“Š ComercioExterior: {total_comex:,} registros")
        logger.info(f"ðŸ’° Total ImportaÃ§Ã£o (USD): ${total_valor_imp:,.2f}")
        logger.info(f"ðŸ’° Total ExportaÃ§Ã£o (USD): ${total_valor_exp:,.2f}")
        logger.info(f"ðŸ“¦ Total Peso ImportaÃ§Ã£o (kg): {total_peso_imp:,.2f}")
        logger.info(f"ðŸ“¦ Total Peso ExportaÃ§Ã£o (kg): {total_peso_exp:,.2f}")
        logger.info(f"ðŸ¢ Empresas: {total_empresas:,} registros")
        logger.info(f"ðŸ“‹ OperacaoComex: {total_ops:,} registros")
        logger.info("="*80)
        
        return {
            "status": "ok",
            "comercio_exterior": {
                "total_registros": total_comex,
                "total_valor_importacao_usd": float(total_valor_imp),
                "total_valor_exportacao_usd": float(total_valor_exp),
                "total_peso_importacao_kg": float(total_peso_imp),
                "total_peso_exportacao_kg": float(total_peso_exp),
            },
            "empresas": {
                "total": total_empresas
            },
            "operacoes_comex": {
                "total": total_ops
            },
            "tem_dados": total_comex > 0 or total_empresas > 0 or total_ops > 0
        }
    except Exception as e:
        logger.error(f"Erro ao validar dados: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erro ao validar dados: {str(e)}")


@app.get("/dashboard/dados-ncm-comexstat")
async def get_dados_ncm_comexstat(
    limite: int = Query(default=100, ge=1, le=1000),
    uf: Optional[str] = Query(default=None),
    tipo: Optional[str] = Query(default=None, description="importacao ou exportacao")
):
    """
    Retorna dados agregados por NCM do arquivo Excel ComexStat.
    """
    try:
        import json
        from pathlib import Path
        
        arquivo_ncm = Path(__file__).parent.parent / "data" / "dados_ncm_comexstat.json"
        
        if not arquivo_ncm.exists():
            return {
                "success": False,
                "message": "Arquivo de dados NCM nÃ£o encontrado. Execute o script de processamento primeiro.",
                "data": []
            }
        
        with open(arquivo_ncm, 'r', encoding='utf-8') as f:
            dados_ncm = json.load(f)
        
        # Aplicar filtros
        if uf:
            dados_ncm = [d for d in dados_ncm if d.get('uf') == uf]
        
        if tipo == 'importacao':
            dados_ncm = [d for d in dados_ncm if d.get('valor_importacao_usd', 0) > 0]
        elif tipo == 'exportacao':
            dados_ncm = [d for d in dados_ncm if d.get('valor_exportacao_usd', 0) > 0]
        
        # Ordenar por valor total e limitar
        dados_ncm.sort(
            key=lambda x: x.get('valor_importacao_usd', 0) + x.get('valor_exportacao_usd', 0),
            reverse=True
        )
        dados_ncm = dados_ncm[:limite]
        
        return {
            "success": True,
            "total": len(dados_ncm),
            "data": dados_ncm
        }
    except Exception as e:
        logger.error(f"Erro ao buscar dados NCM: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Erro ao buscar dados NCM: {str(e)}")


if __name__ == "__main__":
    from loguru import logger
    
    logger.info("Iniciando servidor FastAPI...")
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=settings.debug,
        log_level=settings.log_level.lower()
    )

